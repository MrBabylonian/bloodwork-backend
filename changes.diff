diff --git a/.DS_Store b/.DS_Store
index abf502a..910f19d 100644
Binary files a/.DS_Store and b/.DS_Store differ
diff --git a/changes.diff b/changes.diff
index 18dd7e6..e69de29 100644
--- a/changes.diff
+++ b/changes.diff
@@ -1,3424 +0,0 @@
-diff --git a/app/__pycache__/main.cpython-311.pyc b/app/__pycache__/main.cpython-311.pyc
-index 68c1c66..a896ad5 100644
-Binary files a/app/__pycache__/main.cpython-311.pyc and b/app/__pycache__/main.cpython-311.pyc differ
-diff --git a/app/auth/auth_service.py b/app/auth/auth_service.py
-index 85234c8..2823b72 100644
---- a/app/auth/auth_service.py
-+++ b/app/auth/auth_service.py
-@@ -4,6 +4,7 @@ from app.auth.auth_config import AuthConfig
- from app.auth.password_service import PasswordService
- from app.auth.token_service import TokenService
- from app.models.database_models import ApprovalStatus, User, UserRole
-+from app.repositories.admin_repository import AdminRepository
- from app.repositories.refresh_token_repository import RefreshTokenRepository
- from app.repositories.user_repository import UserRepository
- from app.utils.logger_utils import ApplicationLogger
-@@ -12,9 +13,10 @@ from app.utils.logger_utils import ApplicationLogger
- class AuthService:
-     """Main authentication service"""
- 
--    def __init__(self, user_repo: UserRepository, refresh_token_repo: RefreshTokenRepository,
--                 config: AuthConfig | None = None):
-+    def __init__(self, user_repo: UserRepository, admin_repo: AdminRepository,
-+                 refresh_token_repo: RefreshTokenRepository, config: AuthConfig | None = None):
-         self.user_repo = user_repo
-+        self.admin_repo = admin_repo
-         self.refresh_token_repo = refresh_token_repo
-         self.config = config or AuthConfig()
-         self.password_service = PasswordService()
-@@ -53,23 +55,38 @@ class AuthService:
-                     device_info: str | None = None, ip_address: str | None = None) -> dict | None:
-         """Authenticate user and return tokens"""
-         try:
--            # Get user by username
-+            # Check users collection first
-             user = await self.user_repo.get_by_username(username)
-+            is_admin = False
-+
-+            # If not found in users, check admins collection
-+            if not user:
-+                user = await self.admin_repo.get_by_username(username)
-+                is_admin = True
-+
-             if not user:
-                 self.logger.warning(
-                     f"Login attempt with non-existent username: {username}")
-                 return None
- 
--            # Check if user is approved and active
--            if user.approval_status != ApprovalStatus.APPROVED:
--                self.logger.warning(
--                    f"Login attempt by unapproved user: {username}")
--                return None
--
--            if not user.is_active:
--                self.logger.warning(
--                    f"Login attempt by inactive user: {username}")
--                return None
-+            # Validate user status
-+            if is_admin:
-+                # Admins only need to be active
-+                if not user.is_active:
-+                    self.logger.warning(
-+                        f"Login attempt by inactive admin: {username}")
-+                    return None
-+            else:
-+                # Regular users need approval and active status
-+                from app.models.database_models import User
-+                if isinstance(user, User) and user.approval_status != ApprovalStatus.APPROVED:
-+                    self.logger.warning(
-+                        f"Login attempt by unapproved user: {username}")
-+                    return None
-+                if not user.is_active:
-+                    self.logger.warning(
-+                        f"Login attempt by inactive user: {username}")
-+                    return None
- 
-             # Verify password
-             if not self.password_service.verify_password(password, user.hashed_password):
-@@ -105,7 +122,10 @@ class AuthService:
-             )
- 
-             # Update last login
--            await self.user_repo.update_last_login(user.id)
-+            if is_admin:
-+                await self.admin_repo.update_last_login(user.id)
-+            else:
-+                await self.user_repo.update_last_login(user.id)
- 
-             self.logger.info(f"User logged in successfully: {username}")
- 
-@@ -201,19 +221,57 @@ class AuthService:
-     async def verify_access_token(self, token: str) -> dict | None:
-         """Verify access token and return user info"""
-         try:
-+            self.logger.info("Starting token verification process")
-+
-             payload = self.token_service.verify_token(token)
--            if not payload or not self.token_service.is_access_token(payload):
-+            if not payload:
-+                self.logger.warning(
-+                    "Token verification failed - invalid token format or signature")
-+                return None
-+
-+            self.logger.info(
-+                "Token decoded successfully, checking if access token")
-+
-+            if not self.token_service.is_access_token(payload):
-+                self.logger.warning(
-+                    "Token verification failed - not an access token")
-                 return None
- 
-             # Get user to ensure they're still active
-             user_id = self.token_service.get_user_id_from_payload(payload)
-             if not user_id:
-+                self.logger.warning(
-+                    "Token verification failed - no user ID in payload")
-                 return None
- 
-+            self.logger.info(f"Retrieved user_id from token: {user_id}")
-+
-             user = await self.user_repo.get_by_id(user_id)
--            if not user or not user.is_active or user.approval_status != ApprovalStatus.APPROVED:
-+            if not user:
-+                # Check if it's an admin account
-+                self.logger.info(
-+                    "User not found in users collection, checking admin collection")
-+                admin = await self.admin_repo.get_by_id(user_id)
-+                if not admin:
-+                    self.logger.warning(
-+                        f"Token verification failed - user/admin not found: {user_id}")
-+                    return None
-+                user = admin
-+
-+            if not user.is_active:
-+                self.logger.warning(
-+                    f"Token verification failed - user not active: {user_id}")
-+                return None
-+
-+            # Only check approval status for regular users, not admins
-+            from app.models.database_models import User
-+            if isinstance(user, User) and user.approval_status != ApprovalStatus.APPROVED:
-+                self.logger.warning(
-+                    f"Token verification failed - user not approved: {user_id}, status: {user.approval_status}")
-                 return None
- 
-+            self.logger.info(
-+                f"Token verification successful for user: {user.username}")
-             return {
-                 "user_id": user_id,
-                 "username": self.token_service.get_username_from_payload(payload),
-diff --git a/app/dependencies/auth_dependencies.py b/app/dependencies/auth_dependencies.py
-index 02c8c3c..a8c8ce1 100644
---- a/app/dependencies/auth_dependencies.py
-+++ b/app/dependencies/auth_dependencies.py
-@@ -1,12 +1,11 @@
--from fastapi import Depends, HTTPException, status
--from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
--
--from app.auth.auth_service import AuthService
- from app.auth.auth_config import AuthConfig
-+from app.auth.auth_service import AuthService
- from app.config.database_config import DatabaseConfig
- from app.models.database_models import UserRole
- from app.repositories import RepositoryFactory
- from app.services.database_service import DatabaseService
-+from fastapi import Depends, HTTPException, status
-+from fastapi.security import HTTPAuthorizationCredentials, HTTPBearer
- 
- # Security scheme for token extraction
- security = HTTPBearer()
-@@ -41,6 +40,7 @@ def get_auth_service(repo_factory: RepositoryFactory = Depends(get_repository_fa
-         config = AuthConfig()
-         _auth_service = AuthService(
-             user_repo=repo_factory.user_repository,
-+            admin_repo=repo_factory.admin_repository,
-             refresh_token_repo=repo_factory.refresh_token_repository,
-             config=config
-         )
-@@ -52,16 +52,26 @@ async def get_current_user(
-     auth_service: AuthService = Depends(get_auth_service)
- ) -> dict:
-     """Get current authenticated user from JWT token"""
-+    from app.utils.logger_utils import ApplicationLogger
-+    logger = ApplicationLogger.get_logger(__name__)
-+
-     token = credentials.credentials
-+    logger.info(
-+        f"Attempting to verify token: {token[:20]}..." if token else "No token provided")
-+
-     user_info = await auth_service.verify_access_token(token)
--    
-+
-     if not user_info:
-+        logger.warning(
-+            f"Token verification failed for token: {token[:20]}..." if token else "No token")
-         raise HTTPException(
-             status_code=status.HTTP_401_UNAUTHORIZED,
-             detail="Invalid or expired token",
-             headers={"WWW-Authenticate": "Bearer"},
-         )
--    
-+
-+    logger.info(
-+        f"Token verified successfully for user: {user_info.get('username', 'unknown')}")
-     return user_info
- 
- 
-@@ -85,22 +95,38 @@ def require_role(required_role: UserRole):
-     return role_checker
- 
- 
--# Pre-configured role dependencies  
-+# Pre-configured role dependencies
- def require_veterinarian():
-     return require_role(UserRole.VETERINARIAN)
- 
-+
- def require_technician():
-     return require_role(UserRole.VETERINARY_TECHNICIAN)
- 
-+
- def require_admin_role():
-     """Dependency that requires admin role"""
-     async def admin_checker(current_user: dict = Depends(get_current_user)) -> dict:
-         # Check if user has admin role or is actually an admin
-         user_role = current_user.get("role")
--        if user_role not in ["admin", UserRole.VETERINARIAN]:  # Allow vets to have admin functions
-+        # Allow vets to have admin functions
-+        if user_role not in ["admin", UserRole.VETERINARIAN]:
-             raise HTTPException(
-                 status_code=status.HTTP_403_FORBIDDEN,
-                 detail="Access denied. Admin privileges required."
-             )
-         return current_user
-     return admin_checker
-+
-+
-+def require_admin_or_veterinarian():
-+    """Dependency that requires admin or veterinarian role"""
-+    async def admin_or_vet_checker(current_user: dict = Depends(get_current_user)) -> dict:
-+        user_role = current_user.get("role")
-+        if user_role not in ["admin", UserRole.VETERINARIAN]:
-+            raise HTTPException(
-+                status_code=status.HTTP_403_FORBIDDEN,
-+                detail="Access denied. Only administrators and veterinarians can perform this action."
-+            )
-+        return current_user
-+    return admin_or_vet_checker
-diff --git a/app/main.py b/app/main.py
-index 098b47a..2a892c5 100644
---- a/app/main.py
-+++ b/app/main.py
-@@ -8,11 +8,11 @@ Last updated: 2025-06-17
- Author: Bedirhan Gilgiler
- """
- 
--from fastapi import FastAPI
--
- from app.routers import auth_router, patient_router
- from app.routers.analysis_router import AnalysisRouter
- from app.utils.logger_utils import ApplicationLogger
-+from fastapi import FastAPI
-+from fastapi.middleware.cors import CORSMiddleware
- 
- 
- class BloodworkAnalyzerApplication:
-@@ -27,6 +27,7 @@ class BloodworkAnalyzerApplication:
-         """Initialize the application with default configuration."""
-         self._logger = ApplicationLogger.setup_logging().getChild("main")
-         self._app = self._create_fastapi_instance()
-+        self._configure_middleware()
-         self._configure_routers()
-         self._configure_events()
- 
-@@ -43,6 +44,18 @@ class BloodworkAnalyzerApplication:
-             version="1.0.0"
-         )
- 
-+    def _configure_middleware(self) -> None:
-+        """Configure application middleware including CORS for development."""
-+        # CORS configuration for development
-+        self._app.add_middleware(
-+            CORSMiddleware,
-+            allow_origins="*",
-+            allow_credentials=True,
-+            allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
-+            allow_headers=["*"],
-+        )
-+        self._logger.info("CORS middleware configured for development")
-+
-     def _configure_routers(self) -> None:
-         """Configure and mount all application routers."""
-         # Legacy analysis router (original functionality)
-@@ -50,7 +63,7 @@ class BloodworkAnalyzerApplication:
-         self._app.include_router(
-             analysis_router.get_router(),
-             prefix="/analysis",
--            tags=["Legacy Analysis (Deprecated)"],
-+            tags=["Legacy Analysis"],
-         )
- 
-         # Authentication and patient routers
-diff --git a/app/models/database_models.py b/app/models/database_models.py
-index 0bc79e3..2cd0793 100644
---- a/app/models/database_models.py
-+++ b/app/models/database_models.py
-@@ -55,8 +55,8 @@ class AiDiagnostic(BaseModel):
-     sequence_number: int  # Order of tests for this patient (1, 2, 3...)
-     test_date: datetime
- 
--    # Full OpenAI Analysis
--    openai_analysis: dict[str, any]  # type: ignore
-+    # Full OpenAI Analysis (stored as JSON string to preserve exact format)
-+    openai_analysis: str = ""  # JSON string from OpenAI API
- 
-     # PDF metadata
-     pdf_metadata: dict[str, any] = {  # type: ignore
-diff --git a/app/repositories/patient_repository.py b/app/repositories/patient_repository.py
-index df77f89..4aa9b09 100644
---- a/app/repositories/patient_repository.py
-+++ b/app/repositories/patient_repository.py
-@@ -1,11 +1,10 @@
- from datetime import datetime, timezone
- 
--from bson import ObjectId
--from pymongo.errors import DuplicateKeyError
--
- from app.models.database_models import Patient
- from app.services.database_service import DatabaseService
- from app.utils.logger_utils import ApplicationLogger
-+from bson import ObjectId
-+from pymongo.errors import DuplicateKeyError
- 
- 
- class PatientRepository:
-@@ -74,6 +73,33 @@ class PatientRepository:
-             self.logger.error(f"Error getting patients by user_id: {e}")
-             return []
- 
-+    async def get_all(self) -> list[Patient]:
-+        """Get all active patients"""
-+        try:
-+            # Debug logging to see what database and collection we're using
-+            database_name = self.db_service.database.name if self.db_service.database is not None else 'Unknown'
-+            self.logger.info(f"Querying database: {database_name}")
-+            self.logger.info(f"Querying collection: {self.collection.name}")
-+
-+            cursor = self.collection.find(
-+                {"is_active": True}
-+            ).sort("created_at", -1)
-+
-+            docs = await cursor.to_list(length=None)
-+            self.logger.info(f"Found {len(docs)} patient documents")
-+
-+            # Debug: let's see what the first document looks like
-+            if docs:
-+                first_doc = docs[0]
-+                self.logger.info(
-+                    f"First document: patient_id={first_doc.get('patient_id')}, created_by={first_doc.get('created_by')}, assigned_to={first_doc.get('assigned_to')}")
-+
-+            return [Patient(**doc) for doc in docs]
-+
-+        except Exception as e:
-+            self.logger.error(f"Error getting all patients: {e}")
-+            return []
-+
-     async def search_by_name(self, name: str) -> list[Patient]:
-         """Search patients by name (text search)"""
-         try:
-diff --git a/app/routers/__pycache__/analysis_router.cpython-311.pyc b/app/routers/__pycache__/analysis_router.cpython-311.pyc
-index 0e93a9f..8928ade 100644
-Binary files a/app/routers/__pycache__/analysis_router.cpython-311.pyc and b/app/routers/__pycache__/analysis_router.cpython-311.pyc differ
-diff --git a/app/routers/analysis_router.py b/app/routers/analysis_router.py
-index e8f4ec2..3d91752 100644
---- a/app/routers/analysis_router.py
-+++ b/app/routers/analysis_router.py
-@@ -9,12 +9,12 @@ Last updated: 2025-06-17
- Author: Bedirhan Gilgiler
- """
- 
--from pathlib import Path
- from typing import Optional
- 
- from fastapi import (
-     APIRouter,
-     BackgroundTasks,
-+    Depends,
-     File,
-     HTTPException,
-     Response,
-@@ -22,6 +22,8 @@ from fastapi import (
- )
- from fastapi.responses import JSONResponse
- 
-+from app.dependencies.auth_dependencies import get_current_user
-+from app.models.database_models import User
- from app.services.pdf_analysis_service import BloodworkPdfAnalysisService
- from app.utils.logger_utils import ApplicationLogger
- 
-@@ -53,17 +55,18 @@ class AnalysisRouter:
-         )
- 
-         self._router.add_api_route(
--            "/pdf_analysis_result/{uuid}",
-+            "/pdf_analysis_result/{diagnostic_id}",
-             self.get_analysis_result,
-             methods=["GET"],
-             summary="Get analysis result",
--            description="Retrieve the analysis result for a specific UUID"
-+            description="Retrieve the analysis result for a specific diagnostic ID"
-         )
- 
-     async def analyze_pdf_file_endpoint(
-         self,
-         file: UploadFile = File(...),
--        background_tasks: BackgroundTasks = BackgroundTasks()
-+        background_tasks: BackgroundTasks = BackgroundTasks(),
-+        current_user: User = Depends(get_current_user)
-     ) -> JSONResponse:
-         """
-         Endpoint to analyze uploaded PDF bloodwork files.
-@@ -75,9 +78,10 @@ class AnalysisRouter:
-         Args:
-             file (UploadFile): The uploaded PDF file
-             background_tasks (BackgroundTasks): FastAPI background task manager
-+            current_user (User): Authenticated user from JWT token
- 
-         Returns:
--            JSONResponse: Response with UUID and status message
-+            JSONResponse: Response with diagnostic ID and status message
- 
-         Raises:
-             HTTPException: If file validation or processing fails
-@@ -100,12 +104,12 @@ class AnalysisRouter:
- 
-             # Process the PDF file
-             result = await self._pdf_analysis_service.process_uploaded_pdf_in_background(
--                file, background_tasks
-+                file, background_tasks, current_user
-             )
- 
-             self._logger.info(
-                 f"PDF analysis initiated successfully for: {file.filename} "
--                f"(UUID: {result['pdf_uuid']})"
-+                f"(ID: {result['diagnostic_id']})"
-             )
- 
-             return JSONResponse(content=result)
-@@ -142,18 +146,20 @@ class AnalysisRouter:
- 
-     async def get_analysis_result(
-         self,
--        uuid: str,
--        structured: Optional[bool] = False
-+        diagnostic_id: str,
-+        structured: Optional[bool] = False,
-+        current_user: User = Depends(get_current_user)
-     ) -> Response:
-         """
--        Endpoint to retrieve analysis results by UUID.
-+        Endpoint to retrieve analysis results by diagnostic ID.
- 
--        This endpoint checks for the existence of analysis results and returns
--        them if available. If results are not ready, it returns a 202 status.
-+        This endpoint retrieves analysis results from the database instead of 
-+        the file system, providing better data persistence and access control.
- 
-         Args:
--            uuid (str): The analysis UUID to retrieve results for
-+            diagnostic_id (str): The diagnostic ID to retrieve results for
-             structured (Optional[bool]): Whether to return structured data (unused)
-+            current_user (User): Authenticated user from JWT token
- 
-         Returns:
-             Response: Analysis results or status message
-@@ -162,7 +168,7 @@ class AnalysisRouter:
-             HTTPException: If result retrieval fails
- 
-         Example:
--            GET /analysis/pdf_analysis_result/12345678-1234-1234-1234-123456789012
-+            GET /analysis/pdf_analysis_result/60a1b2c3d4e5f6789012345a
- 
-             Response (if ready):
-             HTTP 200 - Analysis result content
-@@ -171,62 +177,36 @@ class AnalysisRouter:
-             HTTP 202 - {"detail": "Risultato non ancora pronto"}
-         """
-         try:
--            # Check for the new model output filename first
--            result_file_path = Path(
--                f"data/blood_work_pdfs/{uuid}/model_output.json")
-+            # Get analysis result from database
-+            result = await self._pdf_analysis_service.get_analysis_result_from_database(
-+                diagnostic_id, current_user
-+            )
- 
--            # Check if any result file exists
--            if not result_file_path.exists():
-+            if result is None:
-                 self._logger.info(
--                    f"Analysis result not ready yet for UUID: {uuid}")
-+                    f"Analysis result not ready yet for diagnostic ID: {diagnostic_id}")
-                 return JSONResponse(
-                     status_code=202,
-                     content={"detail": "Risultato non ancora pronto"}
-                 )
- 
--            # Read and return the result
--            analysis_result = self._read_analysis_result_file(result_file_path)
--
-             self._logger.info(
--                f"Analysis result successfully retrieved for UUID: {uuid} "
--                f"from file: {result_file_path.name}"
-+                f"Analysis result successfully retrieved for diagnostic ID: {diagnostic_id}"
-             )
- 
-             return Response(
--                content=analysis_result,
-+                content=result,
-                 media_type="application/json"
-             )
- 
-         except Exception as error:
--            error_msg = f"Error retrieving analysis result for UUID: {uuid}"
-+            error_msg = f"Error retrieving analysis result for diagnostic ID: {diagnostic_id}"
-             self._logger.exception(f"{error_msg} - Error: {error}")
-             raise HTTPException(
-                 status_code=500,
-                 detail=f"Errore interno del server: {str(error)}"
-             ) from error
- 
--    def _read_analysis_result_file(self, file_path: Path) -> str:
--        """
--        Read the analysis result from file.
--
--        Args:
--            file_path (Path): Path to the result file
--
--        Returns:
--            str: Content of the result file
--
--        Raises:
--            RuntimeError: If file reading fails
--        """
--        try:
--            with open(file_path, "r", encoding="utf-8") as result_file:
--                return result_file.read()
--
--        except Exception as error:
--            error_msg = f"Failed to read result file: {file_path}"
--            self._logger.exception(f"{error_msg} - Error: {error}")
--            raise RuntimeError(error_msg) from error
--
-     def get_router(self) -> APIRouter:
-         """
-         Get the configured APIRouter instance.
-diff --git a/app/routers/patient_router.py b/app/routers/patient_router.py
-index 4afde45..b935d20 100644
---- a/app/routers/patient_router.py
-+++ b/app/routers/patient_router.py
-@@ -7,18 +7,17 @@ following veterinary workflow patterns and role-based access control.
- 
- from typing import List
- 
--from fastapi import APIRouter, Depends, HTTPException, status
--
- from app.dependencies.auth_dependencies import (
-     get_current_user,
-     get_repository_factory,
-+    require_admin_or_veterinarian,
-     require_admin_role,
--    require_veterinarian,
- )
- from app.models.database_models import Patient, UserRole
- from app.repositories import RepositoryFactory
- from app.schemas.patient_schemas import PatientCreate, PatientResponse, PatientUpdate
- from app.utils.logger_utils import ApplicationLogger
-+from fastapi import APIRouter, Depends, HTTPException, status
- 
- # Create router
- router = APIRouter(prefix="/api/v1/patients", tags=["Patient Management"])
-@@ -28,13 +27,13 @@ logger = ApplicationLogger.get_logger(__name__)
- @router.post("/", response_model=PatientResponse, status_code=status.HTTP_201_CREATED)
- async def create_patient(
-     patient_data: PatientCreate,
--    current_user: dict = Depends(get_current_user),
-+    current_user: dict = Depends(require_admin_or_veterinarian()),
-     repo_factory: RepositoryFactory = Depends(get_repository_factory)
- ):
-     """
-     Create a new patient.
- 
--    Protected route - requires authentication.
-+    Protected route - only admins and veterinarians can create patients.
-     Patient is automatically assigned to the creating user.
-     """
-     patient_repo = repo_factory.patient_repository
-@@ -84,17 +83,17 @@ async def create_patient(
- 
- 
- @router.get("/", response_model=List[PatientResponse])
--async def get_my_patients(
-+async def get_all_patients(
-     current_user: dict = Depends(get_current_user),
-     repo_factory: RepositoryFactory = Depends(get_repository_factory)
- ):
-     """
--    Get all patients assigned to current user.
-+    Get all patients.
- 
--    Protected route - users see only their assigned patients.
-+    Protected route - all authenticated users can view all patients.
-     """
-     patient_repo = repo_factory.patient_repository
--    patients = await patient_repo.get_by_user_id(current_user["user_id"])
-+    patients = await patient_repo.get_all()
- 
-     return [
-         PatientResponse(
-@@ -128,7 +127,7 @@ async def get_patient(
-     """
-     Get specific patient by ID.
- 
--    Protected route - users can only access their assigned patients.
-+    Protected route - all authenticated users can view any patient.
-     """
-     patient_repo = repo_factory.patient_repository
- 
-@@ -143,15 +142,6 @@ async def get_patient(
-             detail="Patient not found"
-         )
- 
--    # Check if user has access to this patient
--    if str(patient.assigned_to) != current_user["user_id"]:
--        # Allow veterinarians to access any patient
--        if current_user.get("role") != UserRole.VETERINARIAN:
--            raise HTTPException(
--                status_code=status.HTTP_403_FORBIDDEN,
--                detail="Access denied - patient not assigned to you"
--            )
--
-     return PatientResponse(
-         id=str(patient.id),
-         patient_id=patient.patient_id,
-@@ -182,11 +172,11 @@ async def update_patient(
-     """
-     Update patient information.
- 
--    Protected route - users can only update their assigned patients.
-+    Protected route - all authenticated users can update any patient.
-     """
-     patient_repo = repo_factory.patient_repository
- 
--    # Get patient and verify access
-+    # Get patient and verify it exists
-     patient = await patient_repo.get_by_id(patient_id)
-     if not patient:
-         patient = await patient_repo.get_by_patient_id(patient_id)
-@@ -197,14 +187,6 @@ async def update_patient(
-             detail="Patient not found"
-         )
- 
--    # Check access
--    if str(patient.assigned_to) != current_user["user_id"]:
--        if current_user.get("role") != UserRole.VETERINARIAN:
--            raise HTTPException(
--                status_code=status.HTTP_403_FORBIDDEN,
--                detail="Access denied - patient not assigned to you"
--            )
--
-     # Ensure patient has ID
-     if not patient.id:
-         raise HTTPException(
-@@ -311,13 +293,13 @@ async def delete_patient(
- @router.get("/search/{name}", response_model=List[PatientResponse])
- async def search_patients(
-     name: str,
--    current_user: dict = Depends(require_veterinarian()),
-+    current_user: dict = Depends(get_current_user),
-     repo_factory: RepositoryFactory = Depends(get_repository_factory)
- ):
-     """
-     Search patients by name.
- 
--    Protected route - only veterinarians can search all patients.
-+    Protected route - all authenticated users can search patients.
-     """
-     patient_repo = repo_factory.patient_repository
-     patients = await patient_repo.search_by_name(name)
-diff --git a/app/services/__pycache__/pdf_analysis_service.cpython-311.pyc b/app/services/__pycache__/pdf_analysis_service.cpython-311.pyc
-index de2fec7..70cf2d3 100644
-Binary files a/app/services/__pycache__/pdf_analysis_service.cpython-311.pyc and b/app/services/__pycache__/pdf_analysis_service.cpython-311.pyc differ
-diff --git a/app/services/database_service.py b/app/services/database_service.py
-index 27d69c5..60d4025 100644
---- a/app/services/database_service.py
-+++ b/app/services/database_service.py
-@@ -1,4 +1,8 @@
--from motor.motor_asyncio import AsyncIOMotorClient, AsyncIOMotorDatabase
-+from motor.motor_asyncio import (
-+    AsyncIOMotorClient,
-+    AsyncIOMotorDatabase,
-+    AsyncIOMotorGridFSBucket,
-+)
- from pymongo.errors import ConnectionFailure, ServerSelectionTimeoutError
- 
- from app.config.database_config import DatabaseConfig
-@@ -14,6 +18,7 @@ class DatabaseService:
-         self.config = config
-         self.client: AsyncIOMotorClient | None = None
-         self.database: AsyncIOMotorDatabase | None = None
-+        self.gridfs: AsyncIOMotorGridFSBucket | None = None
-         self.logger = ApplicationLogger.get_logger(__name__)
- 
-     async def initialize_database(self) -> bool:
-@@ -80,6 +85,9 @@ class DatabaseService:
-             # Get database reference
-             self.database = self.client[self.config.database_name]
- 
-+            # Initialize GridFS bucket
-+            self.gridfs = AsyncIOMotorGridFSBucket(self.database)
-+
-             self.logger.info(
-                 f"Successfully connected to MongoDB database: {self.config.database_name}")
-             return True
-@@ -143,3 +151,44 @@ class DatabaseService:
-     def refresh_tokens(self):
-         """Get refresh_tokens collection"""
-         return self.get_collection("refresh_tokens")
-+
-+    async def store_pdf_file(self, file_data: bytes, filename: str) -> str:
-+        """
-+        Store PDF file in GridFS
-+
-+        Args:
-+            file_data: PDF file bytes
-+            filename: Original filename
-+
-+        Returns:
-+            str: GridFS file ID
-+        """
-+        if self.gridfs is None:
-+            raise RuntimeError("Database not connected. Call connect() first.")
-+
-+        file_id = await self.gridfs.upload_from_stream(
-+            filename,
-+            file_data,
-+            metadata={"content_type": "application/pdf"}
-+        )
-+
-+        self.logger.info(
-+            f"Stored PDF file {filename} with GridFS ID: {file_id}")
-+        return str(file_id)
-+
-+    async def get_pdf_file(self, file_id: str) -> bytes:
-+        """
-+        Retrieve PDF file from GridFS
-+
-+        Args:
-+            file_id: GridFS file ID
-+
-+        Returns:
-+            bytes: PDF file data
-+        """
-+        if self.gridfs is None:
-+            raise RuntimeError("Database not connected. Call connect() first.")
-+
-+        from bson import ObjectId
-+        grid_out = await self.gridfs.open_download_stream(ObjectId(file_id))
-+        return await grid_out.read()
-diff --git a/app/services/pdf_analysis_service.py b/app/services/pdf_analysis_service.py
-index 36bb7cd..e51aaf5 100644
---- a/app/services/pdf_analysis_service.py
-+++ b/app/services/pdf_analysis_service.py
-@@ -1,22 +1,26 @@
- """
- PDF analysis service for veterinary bloodwork processing.
- 
--This module orchestrates the complete PDF analysis workflow including file
--upload handling, PDF to image conversion, AI analysis, and result storage.
--It maintains the core business logic while ensuring data integrity.
-+This module orchestrates the complete PDF analysis workflow including PDF 
-+storage in database, temporary image extraction, AI analysis, and result storage.
-+It maintains data integrity by storing PDFs in GridFS and analysis results in MongoDB.
- 
--Last updated: 2025-06-17
-+Last updated: 2025-06-18
- Author: Bedirhan Gilgiler
- """
- 
--import json
-+from datetime import datetime, timezone
- from pathlib import Path
--from tempfile import NamedTemporaryFile
-+from tempfile import TemporaryDirectory
- from typing import Dict, List, Optional
--from uuid import uuid4
- 
- from fastapi import BackgroundTasks, HTTPException, UploadFile
- 
-+from app.dependencies.auth_dependencies import (
-+    get_database_service,
-+    get_repository_factory,
-+)
-+from app.models.database_models import AiDiagnostic, User
- from app.services.openai_service import BloodworkAnalysisService
- from app.utils.file_utils import PdfImageConverter
- from app.utils.logger_utils import ApplicationLogger
-@@ -26,28 +30,22 @@ class PdfAnalysisConfiguration:
-     """
-     Configuration settings for PDF analysis operations.
- 
--    This class centralizes all configuration parameters for the PDF analysis
--    workflow, making it easy to modify settings without changing core logic.
-+    This class centralizes configuration parameters for the PDF analysis
-+    workflow with database storage instead of file-based approach.
-     """
- 
-     def __init__(self):
-         """Initialize configuration with default settings."""
--        self.uploads_root_directory = Path("data/blood_work_pdfs")
--        self.model_output_filename = "model_output.json"
-         self.supported_content_type = "application/pdf"
-         self.temp_file_suffix = ".pdf"
- 
--        # Ensure uploads directory exists
--        self.uploads_root_directory.mkdir(parents=True, exist_ok=True)
--
- 
- class BloodworkPdfAnalysisService:
-     """
-     Main service for processing veterinary PDF bloodwork reports.
- 
-     This service handles the complete workflow from PDF upload to AI analysis,
--    maintaining the original functionality while improving code organization
--    and following OOP principles.
-+    storing PDFs in GridFS and results in MongoDB instead of the file system.
-     """
- 
-     def __init__(self):
-@@ -56,75 +54,88 @@ class BloodworkPdfAnalysisService:
-         self._config = PdfAnalysisConfiguration()
-         self._pdf_converter = PdfImageConverter()
-         self._ai_service = BloodworkAnalysisService()
-+        self._db_service = get_database_service()
-+        self._repo_factory = get_repository_factory(self._db_service)
- 
-     async def process_uploaded_pdf_in_background(
-         self,
-         uploaded_file: UploadFile,
--        background_tasks: BackgroundTasks
-+        background_tasks: BackgroundTasks,
-+        current_user: User
-     ) -> Dict[str, str]:
-         """
-         Process an uploaded PDF file and schedule AI analysis in the background.
- 
--        This method handles the initial PDF processing steps synchronously,
--        then schedules the AI analysis to run in the background to avoid
--        blocking the API response.
-+        This method stores the PDF in GridFS, creates a diagnostic record,
-+        then schedules the AI analysis to run in the background.
- 
-         Args:
-             uploaded_file (UploadFile): The uploaded PDF file
-             background_tasks (BackgroundTasks): FastAPI background tasks manager
-+            current_user (User): The authenticated user
- 
-         Returns:
--            Dict[str, str]: Response containing PDF UUID and status message
-+            Dict[str, str]: Response containing diagnostic ID and status message
- 
-         Raises:
-             HTTPException: If file validation or processing fails
--
--        Example:
--            >>> service = BloodworkPdfAnalysisService()
--            >>> result = await service.process_uploaded_pdf_in_background(
--            ...     pdf_file, background_tasks
--            ... )
-         """
-         # Validate file type
-         self._validate_uploaded_file(uploaded_file)
- 
--        # Generate unique identifier for this analysis session
--        analysis_uuid = str(uuid4())
--
-         self._logger.info(
-             f"Starting PDF analysis for: {uploaded_file.filename} "
--            f"(UUID: {analysis_uuid})"
-+            f"by user: {current_user.username}"
-         )
- 
--        temp_pdf_path: Optional[Path] = None
--
-         try:
--            # Create working directory for this analysis
--            analysis_directory = self._create_analysis_directory(analysis_uuid)
-+            # Read PDF file data
-+            pdf_data = await uploaded_file.read()
-+
-+            # Store PDF in GridFS
-+            filename = uploaded_file.filename or "unknown.pdf"
-+            gridfs_id = await self._db_service.store_pdf_file(pdf_data, filename)
-+
-+            # Create diagnostic record (will be linked to patient later)
-+            from bson import ObjectId
-+            diagnostic = AiDiagnostic(
-+                patient_id=ObjectId(),  # Temporary placeholder - will be updated when linked
-+                sequence_number=1,  # Will be updated when linked to patient
-+                test_date=datetime.now(timezone.utc),
-+                openai_analysis="",  # Will be filled by AI analysis
-+                pdf_metadata={
-+                    "original_filename": filename,
-+                    "file_size": len(pdf_data),
-+                    "gridfs_id": gridfs_id,
-+                    "upload_date": datetime.now(timezone.utc)
-+                },
-+                created_by=current_user.id or ObjectId()
-+            )
- 
--            # Save uploaded file to temporary location
--            temp_pdf_path = await self._save_uploaded_file_temporarily(uploaded_file)
-+            # Save diagnostic to database
-+            ai_repo = self._repo_factory.ai_diagnostic_repository
-+            created_diagnostic = await ai_repo.create(diagnostic)
- 
--            # Convert PDF to images
--            image_paths = self._convert_pdf_to_images(
--                temp_pdf_path,
--                analysis_directory,
--                analysis_uuid
--            )
-+            if not created_diagnostic:
-+                raise HTTPException(
-+                    status_code=500,
-+                    detail="Failed to create diagnostic record"
-+                )
- 
-             # Schedule AI analysis in background
-             background_tasks.add_task(
-                 self._perform_ai_analysis_and_save_results,
--                image_paths,
--                analysis_directory,
--                analysis_uuid
-+                str(created_diagnostic.id),
-+                gridfs_id
-             )
- 
-             return {
--                "pdf_uuid": analysis_uuid,
-+                "diagnostic_id": str(created_diagnostic.id),
-                 "message": "Analisi in corso. Torna più tardi per vedere i risultati."
-             }
- 
-+        except HTTPException:
-+            raise
-         except Exception as error:
-             error_msg = f"Failed to process PDF: {uploaded_file.filename}"
-             self._logger.exception(f"{error_msg} - Error: {error}")
-@@ -133,9 +144,39 @@ class BloodworkPdfAnalysisService:
-                 detail="Errore durante l'analisi del PDF"
-             ) from error
- 
--        finally:
--            # Clean up temporary file
--            self._cleanup_temporary_file(temp_pdf_path)
-+    async def get_analysis_result_from_database(
-+        self,
-+        diagnostic_id: str,
-+        current_user: User
-+    ) -> Optional[str]:
-+        """
-+        Retrieve analysis result from database.
-+
-+        Args:
-+            diagnostic_id (str): The diagnostic ID
-+            current_user (User): The authenticated user
-+
-+        Returns:
-+            Optional[str]: JSON string of analysis result or None if not ready
-+        """
-+        try:
-+            ai_repo = self._repo_factory.ai_diagnostic_repository
-+            diagnostic = await ai_repo.get_by_id(diagnostic_id)
-+
-+            if not diagnostic:
-+                return None
-+
-+            # Check if analysis is complete
-+            if not diagnostic.openai_analysis:
-+                return None
-+
-+            # Return the OpenAI analysis as-is (already a JSON string)
-+            return diagnostic.openai_analysis
-+
-+        except Exception as error:
-+            self._logger.exception(
-+                f"Error retrieving analysis result: {error}")
-+            return None
- 
-     def _validate_uploaded_file(self, uploaded_file: UploadFile) -> None:
-         """
-@@ -157,283 +198,121 @@ class BloodworkPdfAnalysisService:
- 
-         self._logger.info(f"File validation passed: {uploaded_file.filename}")
- 
--    def _create_analysis_directory(self, analysis_uuid: str) -> Path:
--        """
--        Create a dedicated directory for this analysis session.
--
--        Args:
--            analysis_uuid (str): Unique identifier for the analysis
--
--        Returns:
--            Path: Path to the created analysis directory
--        """
--        analysis_directory = self._config.uploads_root_directory / analysis_uuid
--        analysis_directory.mkdir(parents=True, exist_ok=True)
--
--        self._logger.info(f"Created analysis directory: {analysis_directory}")
--        return analysis_directory
--
--    async def _save_uploaded_file_temporarily(self, uploaded_file: UploadFile) -> Path:
--        """
--        Save the uploaded file to a temporary location.
--
--        Args:
--            uploaded_file (UploadFile): File to save
--
--        Returns:
--            Path: Path to the temporary file
--
--        Raises:
--            RuntimeError: If file saving fails
--        """
--        try:
--            with NamedTemporaryFile(
--                delete=False,
--                suffix=self._config.temp_file_suffix
--            ) as temp_file:
--                file_content = await uploaded_file.read()
--                temp_file.write(file_content)
--                temp_file_path = Path(temp_file.name)
--
--            self._logger.info(f"Saved temporary file: {temp_file_path}")
--            return temp_file_path
--
--        except Exception as error:
--            error_msg = "Failed to save uploaded file temporarily"
--            self._logger.exception(f"{error_msg}: {error}")
--            raise RuntimeError(error_msg) from error
--
--    def _convert_pdf_to_images(
-+    async def _perform_ai_analysis_and_save_results(
-         self,
--        pdf_path: Path,
--        output_directory: Path,
--        filename_prefix: str
--    ) -> List[Path]:
-+        diagnostic_id: str,
-+        gridfs_id: str
-+    ) -> None:
-         """
--        Convert PDF to high-resolution images.
-+        Perform AI analysis on PDF and save results to database.
- 
--        Args:
--            pdf_path (Path): Path to the PDF file
--            output_directory (Path): Directory for output images
--            filename_prefix (str): Prefix for image filenames
-+        This method retrieves the PDF from GridFS, converts it to images temporarily,
-+        performs AI analysis, saves results to database, and cleans up temporary files.
- 
--        Returns:
--            List[Path]: List of generated image file paths
-+        Args:
-+            diagnostic_id (str): The diagnostic record ID
-+            gridfs_id (str): The GridFS file ID
-         """
-         try:
--            image_paths = self._pdf_converter.convert_pdf_to_image_list(
--                pdf_path,
--                output_directory,
--                filename_prefix
--            )
-+            self._logger.info(
-+                f"Starting AI analysis for diagnostic: {diagnostic_id}")
- 
--            self._logger.info(f"Generated {len(image_paths)} images from PDF")
--            return image_paths
-+            # Retrieve PDF from GridFS
-+            pdf_data = await self._db_service.get_pdf_file(gridfs_id)
- 
--        except Exception as error:
--            error_msg = "Failed to convert PDF to images"
--            self._logger.exception(f"{error_msg}: {error}")
--            raise RuntimeError(error_msg) from error
-+            # Create temporary directory for image processing
-+            with TemporaryDirectory() as temp_dir:
-+                temp_dir_path = Path(temp_dir)
- 
--    async def _perform_ai_analysis_and_save_results(
--        self,
--        image_paths: List[Path],
--        analysis_directory: Path,
--        analysis_uuid: str
--    ) -> None:
--        """
--        Perform AI analysis on images and save results (BACKGROUND TASK).
-+                # Save PDF temporarily
-+                temp_pdf_path = temp_dir_path / "temp.pdf"
-+                with open(temp_pdf_path, "wb") as f:
-+                    f.write(pdf_data)
- 
--        This method runs the AI analysis and saves the raw OpenAI response
--        to model_output.json as specified in your constraints.
-+                # Convert PDF to images
-+                image_paths = self._convert_pdf_to_images_temp(
-+                    temp_pdf_path, temp_dir_path
-+                )
- 
--        Args:
--            image_paths (List[Path]): List of image file paths
--            analysis_directory (Path): Directory for analysis outputs
--            analysis_uuid (str): Unique analysis identifier
--        """
--        try:
--            self._logger.info(
--                f"Starting AI analysis for {len(image_paths)} images "
--                f"(UUID: {analysis_uuid})"
--            )
-+                # Perform AI analysis
-+                analysis_result = await self._ai_service.analyze_bloodwork_images(
-+                    image_paths
-+                )
- 
--            # Perform AI analysis
--            ai_analysis_result = await self._ai_service.analyze_bloodwork_images(
--                image_paths
--            )
-+                # OpenAI already returns structured JSON as per the prompt
-+                # Save the result directly to database
-+                await self._save_analysis_to_database(diagnostic_id, analysis_result)
- 
--            # Save the raw OpenAI response (as per your constraint)
--            await self._save_analysis_result(
--                ai_analysis_result,
--                analysis_directory,
--                analysis_uuid
--            )
-+                # Images are automatically cleaned up when temp directory is deleted
- 
-             self._logger.info(
--                f"AI analysis completed for UUID: {analysis_uuid}")
-+                f"AI analysis completed for diagnostic: {diagnostic_id}")
- 
-         except Exception as error:
--            error_msg = f"AI analysis failed for UUID: {analysis_uuid}"
--            self._logger.exception(f"{error_msg} - Error: {error}")
--
--            # Save error information for debugging
--            await self._save_error_result(
--                error_msg,
--                analysis_directory,
--                analysis_uuid
-+            self._logger.exception(
-+                f"Error during AI analysis for diagnostic {diagnostic_id}: {error}"
-             )
- 
--    async def _save_analysis_result(
-+    def _convert_pdf_to_images_temp(
-         self,
--        analysis_result: str,
--        analysis_directory: Path,
--        analysis_uuid: str
--    ) -> None:
-+        pdf_path: Path,
-+        temp_dir: Path
-+    ) -> List[Path]:
-         """
--        Save the AI analysis result to file.
--
--        This method saves the raw OpenAI response without modification
--        as specified in your constraints.
-+        Convert PDF to images in temporary directory.
- 
-         Args:
--            analysis_result (str): Raw AI analysis result
--            analysis_directory (Path): Directory for output files
--            analysis_uuid (str): Analysis identifier
-+            pdf_path (Path): Path to the PDF file
-+            temp_dir (Path): Temporary directory for images
-+
-+        Returns:
-+            List[Path]: List of image file paths
-         """
-         try:
--            output_file_path = analysis_directory / self._config.model_output_filename
--
--            # Save the raw response without modification (as per constraint)
--            with open(output_file_path, "w", encoding="utf-8") as output_file:
--                output_file.write(analysis_result)
--
--            self._logger.info(
--                f"Analysis result saved to: {output_file_path} "
--                f"(UUID: {analysis_uuid})"
-+            image_paths = self._pdf_converter.convert_pdf_to_image_list(
-+                pdf_path, temp_dir, "page"
-             )
-+            return [Path(path) for path in image_paths]
- 
-         except Exception as error:
--            error_msg = f"Failed to save analysis result for UUID: {analysis_uuid}"
--            self._logger.exception(f"{error_msg} - Error: {error}")
--            raise RuntimeError(error_msg) from error
-+            self._logger.exception(f"Error converting PDF to images: {error}")
-+            raise
- 
--    async def _save_error_result(
-+    async def _save_analysis_to_database(
-         self,
--        error_message: str,
--        analysis_directory: Path,
--        analysis_uuid: str
-+        diagnostic_id: str,
-+        analysis_result: str
-     ) -> None:
-         """
--        Save error information when analysis fails.
-+        Save AI analysis result to database.
- 
-         Args:
--            error_message (str): Error message to save
--            analysis_directory (Path): Directory for output files
--            analysis_uuid (str): Analysis identifier
-+            diagnostic_id (str): The diagnostic record ID
-+            analysis_result (str): The AI analysis result as JSON string
-         """
-         try:
--            error_file_path = analysis_directory / "error.json"
--            error_data = {
--                "error": error_message,
--                "uuid": analysis_uuid,
--                "status": "failed"
--            }
-+            ai_repo = self._repo_factory.ai_diagnostic_repository
- 
--            with open(error_file_path, "w", encoding="utf-8") as error_file:
--                json.dump(error_data, error_file, indent=2, ensure_ascii=False)
-+            # Update diagnostic with analysis result
-+            from bson import ObjectId
-+            diagnostic = await ai_repo.get_by_id(diagnostic_id)
- 
--            self._logger.info(f"Error information saved to: {error_file_path}")
-+            if diagnostic:
-+                # Store the OpenAI response exactly as received (no parsing)
-+                diagnostic.openai_analysis = analysis_result
- 
--        except Exception as save_error:
--            self._logger.exception(
--                f"Failed to save error information: {save_error}")
--
--    def _cleanup_temporary_file(self, temp_file_path: Optional[Path] = None) -> None:
--        """
--        Clean up temporary files.
-+                # Update in database with the original JSON string
-+                await ai_repo.collection.update_one(
-+                    {"_id": ObjectId(diagnostic_id)},
-+                    {"$set": {"openai_analysis": analysis_result}}
-+                )
- 
--        Args:
--            temp_file_path (Optional[Path]): Path to temporary file to remove
--        """
--        if temp_file_path and temp_file_path.exists():
--            try:
--                temp_file_path.unlink()
-                 self._logger.info(
--                    f"Cleaned up temporary file: {temp_file_path}")
--            except Exception as error:
--                self._logger.warning(
--                    f"Failed to cleanup temporary file: {error}")
--
--
--# Legacy compatibility class
--class PdfAnalysisService:
--    """
--    Legacy PDF analysis service for backward compatibility.
--
--    This class provides methods that delegate to the new OOP service
--    while maintaining the original interface.
--    """
--
--    def __init__(self):
--        """Initialize with new service instance."""
--        self._new_service = BloodworkPdfAnalysisService()
--
--    async def analyze_with_openai(
--        self,
--        image_path_list: List[Path],
--        upload_folder: Path,
--        pdf_uuid: str
--    ) -> None:
--        """
--        Legacy method that maintains the exact same functionality.
--
--        This method preserves your original implementation where the
--        OpenAI response is saved to analysis_output.json without modification.
--        """
--        try:
--            logger = ApplicationLogger.get_logger("pdf_analysis_service")
--            logger.info(
--                f"Running OpenAI analysis for blood work images for UUID {pdf_uuid}"
--            )
--
--            # Use the new AI service
--            ai_service = BloodworkAnalysisService()
--            openai_interpretation = await ai_service.analyze_bloodwork_images(
--                image_path_list
--            )
--
--            # Save exactly as in your original implementation
--            analysis_output_path = upload_folder / "analysis_output.json"
--            with open(analysis_output_path, "w", encoding="utf-8") as f:
--                f.write(openai_interpretation)
--
--            logger.info(
--                f"OpenAI interpretation saved to {analysis_output_path}")
-+                    f"Analysis result saved for diagnostic: {diagnostic_id}")
-+            else:
-+                self._logger.error(f"Diagnostic not found: {diagnostic_id}")
- 
-         except Exception as error:
--            logger = ApplicationLogger.get_logger("pdf_analysis_service")
--            logger.exception(
--                f"Failed to run or save OpenAI analysis for UUID: {pdf_uuid} "
--                f"Error: {error}"
--            )
-+            self._logger.exception(
-+                f"Error saving analysis to database: {error}")
-             raise
--
--    async def analyze_uploaded_pdf_file_background(
--        self,
--        file: UploadFile,
--        background_tasks: BackgroundTasks
--    ) -> Dict[str, str]:
--        """
--        Legacy method that delegates to the new service.
--
--        Args:
--            file (UploadFile): Uploaded PDF file
--            background_tasks (BackgroundTasks): Background tasks manager
--
--        Returns:
--            Dict[str, str]: Analysis result with UUID and message
--        """
--        return await self._new_service.process_uploaded_pdf_in_background(
--            file, background_tasks
--        )
-diff --git a/changes.diff b/changes.diff
-index 2375adf..1b9c19c 100644
---- a/changes.diff
-+++ b/changes.diff
-@@ -1,1895 +0,0 @@
--diff --git a/.DS_Store b/.DS_Store
--index 7fb877b..3d7c340 100644
--Binary files a/.DS_Store and b/.DS_Store differ
--diff --git a/.idea/.gitignore b/.idea/.gitignore
--deleted file mode 100644
--index 13566b8..0000000
----- a/.idea/.gitignore
--+++ /dev/null
--@@ -1,8 +0,0 @@
---# Default ignored files
---/shelf/
---/workspace.xml
---# Editor-based HTTP Client requests
---/httpRequests/
---# Datasource local storage ignored files
---/dataSources/
---/dataSources.local.xml
--diff --git a/.idea/bloodwork_analysis.iml b/.idea/bloodwork_analysis.iml
--deleted file mode 100644
--index f8b79e1..0000000
----- a/.idea/bloodwork_analysis.iml
--+++ /dev/null
--@@ -1,10 +0,0 @@
---<?xml version="1.0" encoding="UTF-8"?>
---<module type="PYTHON_MODULE" version="4">
---  <component name="NewModuleRootManager">
---    <content url="file://$MODULE_DIR$">
---      <excludeFolder url="file://$MODULE_DIR$/.venv" />
---    </content>
---    <orderEntry type="jdk" jdkName="Python 3.11 (bloodwork-backend)" jdkType="Python SDK" />
---    <orderEntry type="sourceFolder" forTests="false" />
---  </component>
---</module>
--\ No newline at end of file
--diff --git a/.idea/codeStyles/codeStyleConfig.xml b/.idea/codeStyles/codeStyleConfig.xml
--deleted file mode 100644
--index a55e7a1..0000000
----- a/.idea/codeStyles/codeStyleConfig.xml
--+++ /dev/null
--@@ -1,5 +0,0 @@
---<component name="ProjectCodeStyleConfiguration">
---  <state>
---    <option name="PREFERRED_PROJECT_CODE_STYLE" value="Default" />
---  </state>
---</component>
--\ No newline at end of file
--diff --git a/.idea/inspectionProfiles/Project_Default.xml b/.idea/inspectionProfiles/Project_Default.xml
--deleted file mode 100644
--index 50dc367..0000000
----- a/.idea/inspectionProfiles/Project_Default.xml
--+++ /dev/null
--@@ -1,16 +0,0 @@
---<component name="InspectionProjectProfileManager">
---  <profile version="1.0">
---    <option name="myName" value="Project Default" />
---    <inspection_tool class="Eslint" enabled="true" level="WARNING" enabled_by_default="true" />
---    <inspection_tool class="HtmlUnknownAttribute" enabled="true" level="WARNING" enabled_by_default="true">
---      <option name="myValues">
---        <value>
---          <list size="1">
---            <item index="0" class="java.lang.String" itemvalue="className" />
---          </list>
---        </value>
---      </option>
---      <option name="myCustomValuesEnabled" value="true" />
---    </inspection_tool>
---  </profile>
---</component>
--\ No newline at end of file
--diff --git a/.idea/inspectionProfiles/profiles_settings.xml b/.idea/inspectionProfiles/profiles_settings.xml
--deleted file mode 100644
--index 105ce2d..0000000
----- a/.idea/inspectionProfiles/profiles_settings.xml
--+++ /dev/null
--@@ -1,6 +0,0 @@
---<component name="InspectionProjectProfileManager">
---  <settings>
---    <option name="USE_PROJECT_PROFILE" value="false" />
---    <version value="1.0" />
---  </settings>
---</component>
--\ No newline at end of file
--diff --git a/.idea/misc.xml b/.idea/misc.xml
--deleted file mode 100644
--index 8f7e002..0000000
----- a/.idea/misc.xml
--+++ /dev/null
--@@ -1,7 +0,0 @@
---<?xml version="1.0" encoding="UTF-8"?>
---<project version="4">
---  <component name="Black">
---    <option name="sdkName" value="Python 3.11 (bloodwork_analysis)" />
---  </component>
---  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.11 (bloodwork-backend)" project-jdk-type="Python SDK" />
---</project>
--\ No newline at end of file
--diff --git a/.idea/modules.xml b/.idea/modules.xml
--deleted file mode 100644
--index efbd78f..0000000
----- a/.idea/modules.xml
--+++ /dev/null
--@@ -1,8 +0,0 @@
---<?xml version="1.0" encoding="UTF-8"?>
---<project version="4">
---  <component name="ProjectModuleManager">
---    <modules>
---      <module fileurl="file://$PROJECT_DIR$/.idea/bloodwork_analysis.iml" filepath="$PROJECT_DIR$/.idea/bloodwork_analysis.iml" />
---    </modules>
---  </component>
---</project>
--\ No newline at end of file
--diff --git a/.idea/vcs.xml b/.idea/vcs.xml
--deleted file mode 100644
--index 94a25f7..0000000
----- a/.idea/vcs.xml
--+++ /dev/null
--@@ -1,6 +0,0 @@
---<?xml version="1.0" encoding="UTF-8"?>
---<project version="4">
---  <component name="VcsDirectoryMappings">
---    <mapping directory="$PROJECT_DIR$" vcs="Git" />
---  </component>
---</project>
--\ No newline at end of file
--diff --git a/app/.DS_Store b/app/.DS_Store
--index 8b8413e..dce9106 100644
--Binary files a/app/.DS_Store and b/app/.DS_Store differ
--diff --git a/app/__pycache__/main.cpython-311.pyc b/app/__pycache__/main.cpython-311.pyc
--index bd7c680..88a3a96 100644
--Binary files a/app/__pycache__/main.cpython-311.pyc and b/app/__pycache__/main.cpython-311.pyc differ
--diff --git a/app/main.py b/app/main.py
--index 856d7e2..a7944f8 100644
----- a/app/main.py
--+++ b/app/main.py
--@@ -1,5 +1,6 @@
-- from fastapi import FastAPI
-- from fastapi.middleware.cors import CORSMiddleware
--+
-- from app.routers import analysis_router
-- from app.utils.logger_utils import Logger
-- 
--@@ -8,24 +9,23 @@ logger = Logger.setup_logging().getChild("main")
-- 
-- # Create the FastAPI app instance
-- app = FastAPI(
---	title="Veterinary Bloodwork Analyzer",
---	description="API for processing veterinary PDF blood test reports via vision model",
---	version="1.0.0",
--+    title="Veterinary Bloodwork Analyzer",
--+    description="API for processing veterinary PDF blood test reports via vision model"
-- )
-- 
-- # CORS configuration to allow frontend access
-- app.add_middleware(
---	CORSMiddleware,
---	allow_origins=["https://main.d1wrcuj3ftjjx5.amplifyapp.com"],
---	allow_credentials=True,
---	allow_methods=["GET, POST"],  # Allow GET, POST, etc.
---	allow_headers=["*"],  # Allow custom headers like Content-Type
--+    CORSMiddleware,
--+    allow_origins=["https://main.d1wrcuj3ftjjx5.amplifyapp.com"],
--+    allow_credentials=True,
--+    allow_methods=["GET, POST"],  # Allow GET, POST, etc.
--+    allow_headers=["*"],  # Allow custom headers like Content-Type
-- )
-- 
-- # Mount the router for analysis functionality
-- app.include_router(analysis_router.router, prefix="/analysis")
-- 
---# Optional: log app startup
--+
-- @app.on_event("startup")
-- async def startup_event():
---	logger.info("FastAPI application has started.")
--+    logger.info("FastAPI application has started.")
--diff --git a/app/routers/__pycache__/analysis_router.cpython-311.pyc b/app/routers/__pycache__/analysis_router.cpython-311.pyc
--index 89f0af0..842725a 100644
--Binary files a/app/routers/__pycache__/analysis_router.cpython-311.pyc and b/app/routers/__pycache__/analysis_router.cpython-311.pyc differ
--diff --git a/app/routers/analysis_router.py b/app/routers/analysis_router.py
--index 9d91cba..fa495d9 100644
----- a/app/routers/analysis_router.py
--+++ b/app/routers/analysis_router.py
--@@ -1,69 +1,74 @@
---from fastapi import HTTPException, APIRouter, UploadFile, File, BackgroundTasks
---from fastapi.responses import JSONResponse
-- from pathlib import Path
-- 
---from app.services import pdf_analysis_service
---from app.utils.ec2_instance_controller import Ec2Controller
--+from fastapi import (
--+    APIRouter,
--+    BackgroundTasks,
--+    File,
--+    HTTPException,
--+    Response,
--+    UploadFile,
--+)
--+from fastapi.responses import JSONResponse
--+
--+from app.services.pdf_analysis_service import PdfAnalysisService
-- from app.utils.logger_utils import Logger
-- 
-- logger = Logger.setup_logging().getChild("analysis_router")
-- 
-- router = APIRouter()
-- 
--+pdf_analysis_service = PdfAnalysisService()
--+
-- 
-- @router.post("/pdf_analysis")
-- async def analyze_pdf_file_endpoint(
---		file: UploadFile = File(...),
---		background_tasks: BackgroundTasks = BackgroundTasks()
--+    file: UploadFile = File(...),
--+    background_tasks: BackgroundTasks = BackgroundTasks()
-- ):
---	logger.info(f"Received PDF analysis request: {file.filename}")
---	if file.content_type != "application/pdf":
---		logger.exception(
---			f"Rejected upload: unsupported content type: {file.content_type}")
---		raise HTTPException(status_code = 400,
---							detail = "Solo file PDF sono accettati.")
--+    logger.info(f"Received PDF analysis request: {file.filename}")
--+    if file.content_type != "application/pdf":
--+        logger.exception(
--+            f"Rejected upload: unsupported content type: {file.content_type}")
--+        raise HTTPException(status_code=400,
--+                            detail="Solo file PDF sono accettati.")
-- 
---	try:
---		ec2 = Ec2Controller()
---		ec2.is_inference_instance_running()
---		result = await pdf_analysis_service.analyze_uploaded_pdf_file_background(
---			file, background_tasks)
---		logger.info(
---			f"PDF analysis completed successfully for: {file.filename}")
---		return JSONResponse(content = result)
--+    try:
--+        result = await pdf_analysis_service.analyze_uploaded_pdf_file_background(
--+            file, background_tasks)
--+        logger.info(
--+            f"PDF analysis completed successfully for: {file.filename}")
--+        return JSONResponse(result)
-- 
---	except HTTPException as http_error:
---		logger.error(f"HTTPException: {http_error}")
---		raise
--+    except HTTPException as http_error:
--+        logger.error(f"HTTPException: {http_error}")
--+        raise
-- 
---	except Exception as error:
---		logger.exception("Unexpected error during PDF analysis")
---		raise HTTPException(status_code = 500,
---							detail = f"Errore interno: {error}")
--+    except Exception as error:
--+        logger.exception("Unexpected error during PDF analysis")
--+        raise HTTPException(status_code=500,
--+                            detail=f"Errore interno: {error}")
-- 
-- 
-- @router.get("/pdf_analysis_result/{uuid}")
-- async def get_analysis_result(uuid: str, structured: bool = False):
---	try:
---		result_file = Path(f"data/blood_work_pdfs/{uuid}/model_output.json")
---		if not result_file.exists():
---			logger.info(f"Model output not ready yet for {uuid}")
---			return JSONResponse(status_code = 202,
---								content = {"detail": "Risultato non ancora "
---													 "pronto"
---										   })
---		with open(result_file, "r", encoding = "utf-8") as result_file:
---			result = result_file.read()
--+    try:
--+        result_file = Path(f"data/blood_work_pdfs/{uuid}/analysis_output.json")
--+        if not result_file.exists():
--+            logger.info(f"Model output not ready yet for {uuid}")
--+            return JSONResponse(status_code=202,
--+                                content={"detail": "Risultato non ancora "
--+                                         "pronto"
--+                                         })
--+        with open(result_file, "r", encoding="utf-8") as result_file:
--+            result = result_file.read()
-- 
---		logger.info(f"Model output is successfully read from"
---					f" {result_file.name}")
--+        logger.info(f"Model output is successfully read from"
--+                    f" {result_file.name}")
-- 
---		return {
---			"result": result,
---		}
--+        return Response(content=result)
-- 
---	except Exception as error:
---		logger.exception(
---			f"Errore durante il recupero del risultato per {uuid}")
---		raise HTTPException(status_code = 500,
---							detail = f"Errore interno: {error}")
--+    except Exception as error:
--+        logger.exception(
--+            f"Errore durante il recupero del risultato per {uuid}")
--+        raise HTTPException(status_code=500,
--+                            detail=f"Errore interno: {error}")
--diff --git a/app/services/__pycache__/pdf_analysis_service.cpython-311.pyc b/app/services/__pycache__/pdf_analysis_service.cpython-311.pyc
--index b5a48ae..bc9c851 100644
--Binary files a/app/services/__pycache__/pdf_analysis_service.cpython-311.pyc and b/app/services/__pycache__/pdf_analysis_service.cpython-311.pyc differ
--diff --git a/app/services/__pycache__/vision_model_inference_service.cpython-311.pyc b/app/services/__pycache__/vision_model_inference_service.cpython-311.pyc
--index 06e38d2..e828931 100644
--Binary files a/app/services/__pycache__/vision_model_inference_service.cpython-311.pyc and b/app/services/__pycache__/vision_model_inference_service.cpython-311.pyc differ
--diff --git a/app/services/diagnostic_prompt.txt b/app/services/diagnostic_prompt.txt
--deleted file mode 100644
--index bdb9482..0000000
----- a/app/services/diagnostic_prompt.txt
--+++ /dev/null
--@@ -1,128 +0,0 @@
---Agisci come un medico veterinario specializzato in ematologia, oncologia e medicina interna con oltre 15 anni di esperienza clinica su CANI e GATTI.
---
---⚠️ IMPORTANTE: TUTTE LE RISPOSTE DEVONO ESSERE ESCLUSIVAMENTE IN LINGUA ITALIANA. NON UTILIZZARE ALTRE LINGUE.
---
---◆ INPUT
---Il testo sopra la linea separatrice contiene dati estratti automaticamente da referti emato-chimici, biochimici, citologici e/o istologici scritti in italiano o inglese.
---Questi dati provengono da un'elaborazione automatica di immagini di referti sanitari e contengono valori, unità, range di riferimento e possibili referti clinici.
---
---⚠️ Analizza direttamente i dati forniti senza chiedere ulteriori informazioni.
---⚠️ Se alcuni dati risultano incompleti o assenti, continua comunque l'analisi e inserisci un avviso chiaro che indichi quali dati mancano o sono incerti.
---
---◆ COMPITI
---1. Tabella dei parametri
---Trascrivi in tabella:
---
---Parametro
---
---Valore misurato
---
---Unità
---
---Range di riferimento (come riportato)
---
---Evidenziazione:
---
---✅ normale
---
---⚠️ lievemente alterato
---
---❌ gravemente alterato
---
---Se mancano valore/unità/range, lascia la cella vuota e segnala in fondo all'analisi quali campi erano incompleti o non leggibili.
---
---2. Analisi matematica
---Calcola e interpreta:
---
---BUN/Creatinina
---
---Calcio/Fosforo
---
---Neutrofili/Linfociti
---
---Na/K
---
---Albumina/Globuline
---
---Indica anomalie e loro significato clinico.
---
---3. Interpretazione clinica
---Spiega ogni alterazione significativa
---
---Formula almeno 3 diagnosi differenziali con % di confidenza
---
---Verifica se i pattern sono compatibili con:
---
---Anemia rigenerativa/non rigenerativa
---
---Neoplasie
---
---Pancreatite, diabete, insufficienza epatica/renale
---
---FIV/FeLV, sindromi infiammatorie o immunomediate
---
---4. Integrazione con citologia/istologia
---Se sono presenti, interpreta i referti citologici/istologici e integra i dati ematochimici.
---
---Non ignorare referti che menzionano neoplasia, linfoma o mitosi.
---
---5. Classificazione dell'urgenza
---Classifica il caso: EMERGENZA, URGENZA A BREVE, ROUTINE
---
---Giustifica la scelta basandoti su: alterazioni gravi, segni oncologici, citopenie, elettroliti critici.
---
---6. Piano diagnostico
---Suggerisci esami aggiuntivi con:
---
---Priorità (Alta / Media / Bassa)
---
---Invasività (Alta / Media / Bassa)
---
---7. Terapia iniziale/supporto
---Farmaci (mg/kg, via, durata)
---
---Supplementi/diete raccomandate
---
---Supporti (SAMe, fluidoterapia, ecc.)
---
---8. Follow-up
---Quando ripetere esami
---
---Segni clinici da monitorare
---
---Indicazioni prognostiche
---
---9. Educazione al proprietario
---Spiega in < 250 parole:
---
---Cosa significano i risultati
---
---Se la situazione è grave o gestibile
---
---Quali passi fare ora
---
---10. Bandierine rosse
---Segnala parametri critici (es. PLT < 100, WBC < 4, Na < 130, K+ > 6.0)
---
---11. Contesto
---Considera:
---
---Digiuno, stress da trasporto
---
---Farmaci in uso
---
---Età, razza, stagione
---
---12. Fonti rapide
---Es. "IRIS 2023", "Thrall 2012", "AAHA 2021 oncology"
---
---13. Disclaimer finale
---Analisi automatica basata su referto estratto. Non sostituisce visita clinica veterinaria. Si consiglia valutazione medica diretta.
---
---◆ LINGUA DI USCITA
---Italiano tecnico ma chiaro, adatto a veterinari. NON utilizzare mai altre lingue anche se i dati di input sono in inglese.
---
---◆ SE MANCANO DATI
---Non interrompere l'analisi. Procedi con ciò che è disponibile e aggiungi in fondo alla risposta un box tipo:
---
---🔶 Attenzione: Alcuni dati non erano leggibili o assenti: [elenco parametri]. È consigliata una revisione manuale del referto originale per conferma.
--\ No newline at end of file
--diff --git a/app/services/openai_data_extracting_service.py b/app/services/openai_data_extracting_service.py
--deleted file mode 100644
--index 0ce188e..0000000
----- a/app/services/openai_data_extracting_service.py
--+++ /dev/null
--@@ -1,61 +0,0 @@
---import os
---import base64
---import json
---import requests
---from openai import OpenAI
---from dotenv import load_dotenv
---from pathlib import Path
---
---load_dotenv()
---
---prompt_path: Path = Path("app/services/openai_prompt.txt")
---api_key = os.getenv("OPENAI_API_KEY")
---
---
---def load_prompt_from_file(prompt_path: Path) -> str:
---    with open(prompt_path, "r", encoding="utf-8") as f:
---        return f.read()
---
---
---def image_to_base64(image_path: Path) -> str:
---    with open(image_path, "rb") as f:
---        return base64.b64encode(f.read()).decode()
---
---
---def extract_emogramma_from_image(image_paths: list[Path], prompt_path: Path = prompt_path) -> str:
---    system_prompt: str = load_prompt_from_file(prompt_path)
---
---    image_messages: list[dict] = []
---    for image_path in image_paths:
---        base64_img: str = image_to_base64(image_path)
---        image_messages.append({
---            "type": "image_url",
---            "image_url": {"url": f"data:image/png;base64,{base64_img}"}
---        })
---
---    headers: dict = {
---        "Content-Type": "application/json",
---        "Authorization": f"Bearer {api_key}"
---    }
---
---    payload: dict[str, any] = {
---        "model": "gpt-4o",
---        "messages": [
---            {"role": "system", "content": system_prompt},
---            {
---                "role": "user",
---                "content": [
---                    {"type": "text", "text": "Estrai i dati ematologici e morfologici come specificato nel prompt."}
---                ] + image_messages
---            }
---        ],
---        "temperature": 0.2
---    }
---
---    response: requests.Response = requests.post(
---        "https://api.openai.com/v1/chat/completions",
---        headers=headers,
---        json=payload
---    )
---
---    return response.json()["choices"][0]["message"]["content"].strip()
--diff --git a/app/services/openai_prompt.txt b/app/services/openai_prompt.txt
--deleted file mode 100644
--index 3de4d06..0000000
----- a/app/services/openai_prompt.txt
--+++ /dev/null
--@@ -1,64 +0,0 @@
---🧪 Estrai i dati ematologici da un referto PDF veterinario convertito in immagini. Il referto può avere più pagine. Le immagini sono fornite in ordine.
---
---📌 Il tuo compito è restituire **esclusivamente** i valori ematologici nella seguente struttura JSON:
---
---{
---  "emogramma_quantitativo": {
---    "NOME PARAMETRO": {
---      "value": numero o null,
---      "unit": "unità di misura esattamente come nel referto",
---      "ref_range": "valore minimo - valore massimo"
---    },
---    ...
---  },
---  "morfologia": {
---    "eritrocitaria": {
---      "Parametro": true / false / "+" / "++" / null
---    },
---    "leucocitaria": {
---      "Parametro": true / false / "+" / "++" / null
---    },
---    "piastrinica": {
---      "Parametro": true / false / "+" / "++" / null
---    }
---  }
---}
---
---🎯 Obiettivo:
---- Raccogli tutti i valori di emogramma presenti nel referto, **anche se si trovano su pagine diverse**.
---- ⚠️ Includi SOLO i test dell'emogramma visibili nelle immagini. NON aggiungere altri test che non compaiono nel referto, anche se comuni o standard.
---- Se un parametro appare nel referto ma è vuoto o assente, imposta `value`, `unit` o `ref_range` a `null`.
---- Non includere valori non visibili o inventati.
---- Se una sezione di morfologia ha solo il nome del parametro senza modificatori, imposta il valore a `true`.
---
------
---
---🔹 Istruzioni per la sezione `emogramma_quantitativo`:
---
---- Riporta **esattamente** i nomi dei parametri come appaiono nel referto, inclusi accenti, simboli e unità (es. `"WBC (migliaia/µL)"`).
---- ⚠️ L'unità (`unit`) deve essere **copiata esattamente come nel referto**: `%`, `pg`, `fL`, `g/dL`, `migliaia/µL`, `milioni/µL`, ecc.
---- NON abbreviare, correggere o tradurre i nomi o unità.
---- Se l'unità è accanto al valore senza spazio, separala logicamente ed estraila.
---- ⚠️ NON confondere l'unità con il range di riferimento.
---- NON inventare unità: se non è visibile → `null`.
---- Mantieni l'ordine logico dei parametri (es. RBC → Hgb → HCT → MCV → MCH → MCHC → RDW, ecc.).
---- Se una riga ha solo il nome del parametro senza valore → `"value": null`.
---
------
---
---🔹 Istruzioni per la sezione `morfologia`:
---
---- Dividi in 3 sottosezioni: `"eritrocitaria"`, `"leucocitaria"` e `"piastrinica"`.
---- I valori possono essere:
---  - `true`: parametro visibile nel referto ma senza modificatori
---  - `false`: esplicitamente assente
---  - `"+"`, `"++"`, `"*"`: se così specificato
---  - `null`: se la voce è assente nel referto
---- NON omettere parametri noti. Se non sono menzionati → `false` o `null` (in base al contesto).
---
------
---
---📌 Output finale:
---- JSON ben formattato e validabile
---- Nessuna spiegazione o testo extra
---- Solo il dizionario JSON completo come output
--\ No newline at end of file
--diff --git a/app/services/pdf_analysis_service.py b/app/services/pdf_analysis_service.py
--index d792f86..8d4f0d5 100644
----- a/app/services/pdf_analysis_service.py
--+++ b/app/services/pdf_analysis_service.py
--@@ -1,103 +1,106 @@
---from fastapi import UploadFile, HTTPException, BackgroundTasks
---from uuid import uuid4
-- from pathlib import Path
-- from tempfile import NamedTemporaryFile
---import asyncio
---import json
--+from uuid import uuid4
--+
--+from fastapi import BackgroundTasks, HTTPException, UploadFile
-- 
--+from app.services.openai_service import OpenAIService
-- from app.utils.file_utils import FileConverter
-- from app.utils.logger_utils import Logger
---from app.services.vision_model_inference_service import \
---    RemoveVisionInferenceService
---from app.services.openai_data_extracting_service import extract_emogramma_from_image
-- 
-- logger = Logger.setup_logging().getChild("pdf_analysis_service")
-- 
-- PDF_UPLOADS_ROOT_DIRECTORY: Path = Path("data/blood_work_pdfs")
-- PDF_UPLOADS_ROOT_DIRECTORY.mkdir(parents=True, exist_ok=True)
-- 
---VISION_SERVER_URL = "http://51.21.18.6:4000"
---remote_vision_inference_service = RemoveVisionInferenceService(
---    VISION_SERVER_URL)
---
---
---def call_inference_and_save_output(
---    extracted_bloodwork_values: str,
---    upload_folder: Path,
---    pdf_uuid: str
---) -> None:
---    try:
---        logger.info(
---            f"Running inference using extracted blood work values for UUID {pdf_uuid}...")
-- 
---        loop = asyncio.new_event_loop()
---        asyncio.set_event_loop(loop)
---
---        model_response: dict[str, str] = loop.run_until_complete(
---            remote_vision_inference_service.run_remote_inference(
---                bloodwork_values=extracted_bloodwork_values,
---                model_name="deepseek-r1:32b"
--+class PdfAnalysisService:
--+    def __init__(self) -> None:
--+        self.openai_service = OpenAIService()
--+        self.uploads_directory = PDF_UPLOADS_ROOT_DIRECTORY
--+
--+    async def analyze_with_openai(
--+            self,
--+            image_path_list: list[Path],
--+            upload_folder: Path,
--+            pdf_uuid: str
--+    ) -> None:
--+        """
--+            Run OpenAI analysis on the blood work images and save the output
--+        """
--+        try:
--+            logger.info(
--+                f"Running OpenAI analysis for blood work images for UUID {pdf_uuid}")
--+
--+            openai_interpretation = await self.openai_service.interpret_bloodwork_via_openai(image_path_list)
--+
--+            print(type(openai_interpretation))
--+
--+            analysis_output_path: Path = upload_folder / "analysis_output.json"
--+            with open(analysis_output_path, "w", encoding="utf-8") as f:
--+                try:
--+                    f.write(openai_interpretation)
--+                except Exception as error:
--+                    logger.exception(
--+                        f"Failed to write OpenAI interpretation to file: {error}")
--+                    raise
--+
--+            logger.info(
--+                f"OpenAI interpreation saved to {analysis_output_path}")
--+        except Exception as error:
--+            logger.exception(
--+                f"Failed to run or save OpenAI analysis for UUID: {pdf_uuid} Error: {error}"
--             )
---        )
---
---        output_data: dict[str, str] = model_response
---
---        model_output_path: Path = upload_folder / "model_output.json"
---        with open(model_output_path, "w", encoding="utf-8") as f:
---            json.dump(output_data, f, ensure_ascii=False)
---
---        logger.info(f"Model output saved to {model_output_path}")
---
---    except Exception as error:
---        logger.exception(
---            f"Failed to run or save inference for UUID: {pdf_uuid} Error: {error}")
---        raise
---
---
---async def analyze_uploaded_pdf_file_background(
---    file: UploadFile,
---    background_tasks: BackgroundTasks
---) -> dict[str, str]:
---    try:
---        pdf_uuid: str = str(uuid4())
---        upload_folder: Path = PDF_UPLOADS_ROOT_DIRECTORY / pdf_uuid
---        upload_folder.mkdir(parents=True, exist_ok=True)
---
---        with NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
---            content = await file.read()
---            tmp.write(content)
---            tmp_path: Path = Path(tmp.name)
---
---        logger.info(f"Received PDF. Temporary file created at {tmp_path}")
---
---        image_path_list: list[Path] = FileConverter.convert_pdf_to_image_list(
---            str(tmp_path),
---            output_folder=upload_folder,
---            base_filename_prefix=pdf_uuid
---        )
---        logger.info(f"Converted to {len(image_path_list)} image(s)")
---
---        tmp_path.unlink(missing_ok=True)
---
---        extracted_bloodwork_values = extract_emogramma_from_image(
---            image_path_list)
---
---        logger.info("Extracting blood work values via OpenAI API")
--+            raise
--+
--+    async def analyze_uploaded_pdf_file_background(
--+            self,
--+            file: UploadFile,
--+            background_tasks: BackgroundTasks
--+    ) -> dict[str, str]:
--+        """
--+        Process an uploaded PDF file and run analysis in the background
--+        """
--+        tmp_path = None
--+        try:
--+            pdf_uuid: str = str(uuid4())
--+            upload_folder: Path = self.uploads_directory / pdf_uuid
--+            upload_folder.mkdir(parents=True, exist_ok=True)
--+
--+            with NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
--+                content = await file.read()
--+                tmp.write(content)
--+                tmp_path = Path(tmp.name)
--+
--+            logger.info(f"Received PDF. Temporary file created at {tmp_path}")
--+
--+            image_path_list: list[Path] = FileConverter.convert_pdf_to_image_list(
--+                tmp_path,
--+                upload_folder,
--+                pdf_uuid
--+            )
--+            logger.info(f"Converted to {len(image_path_list)} image(s)")
-- 
---        background_tasks.add_task(call_inference_and_save_output,
---                                  extracted_bloodwork_values,
---                                  upload_folder,
---                                  pdf_uuid)
--+            if tmp_path.exists():
--+                tmp_path.unlink(missing_ok=True)
-- 
---        return {
---            "pdf_uuid": pdf_uuid,
---            "message": "Analisi in corso. Torna più tardi per vedere i risultati."
---        }
--+            # Run OpenAI analysis in the background
--+            background_tasks.add_task(
--+                self.analyze_with_openai,
--+                image_path_list,
--+                upload_folder,
--+                pdf_uuid
--+            )
-- 
---    except Exception as error:
---        logger.error(f"Failed to process PDF: {error}")
---        raise HTTPException(status_code=500,
---                            detail="Errore interno durante l'analisi")
---    finally:
---        if tmp_path.exists():
---            tmp_path.unlink(missing_ok=True)
--+            return {
--+                "pdf_uuid": pdf_uuid,
--+                "message": "Analisi in corso. Torna più tardi per vedere i risultati."
--+            }
--+        except Exception as error:
--+            logger.error(f"Failed to process PDF. Error: {error}")
--+            raise HTTPException(
--+                status_code=500, detail="Errore durante l'analisi")
--+
--+        finally:
--+            if tmp_path and tmp_path.exists():
--+                tmp_path.unlink(missing_ok=True)
--diff --git a/app/services/vision_model_inference_service.py b/app/services/vision_model_inference_service.py
--index a299e26..d43ac82 100644
----- a/app/services/vision_model_inference_service.py
--+++ b/app/services/vision_model_inference_service.py
--@@ -1,12 +1,13 @@
---from pathlib import Path
-- import re
--+from pathlib import Path
--+
-- import httpx
-- 
-- from app.utils.logger_utils import Logger
-- 
-- logger = Logger.setup_logging().getChild("vision_model_inference_service")
-- 
---prompt_file_path: Path = Path("app/services/diagnostic_prompt.txt")
--+prompt_file_path: Path = Path("app/prompts/diagnostic_prompt.txt")
-- with open(prompt_file_path, "r", encoding="utf-8") as prompt_file:
--     prompt: str = prompt_file.read()
-- 
--@@ -21,7 +22,7 @@ def clean_model_response(model_response: dict[str, str]) -> dict[str, str]:
--     """
-- 
--     try:
---        logger.info(f"Cleaning model response for frontend")
--+        logger.info("Cleaning model response for frontend")
-- 
--         # Remove ANSI terminal escape sequences
--         ansi_escape_pattern: re.Pattern = re.compile(
--diff --git a/app/utils/__pycache__/file_utils.cpython-311.pyc b/app/utils/__pycache__/file_utils.cpython-311.pyc
--index 3e28062..64f8368 100644
--Binary files a/app/utils/__pycache__/file_utils.cpython-311.pyc and b/app/utils/__pycache__/file_utils.cpython-311.pyc differ
--diff --git a/app/utils/__pycache__/logger_utils.cpython-311.pyc b/app/utils/__pycache__/logger_utils.cpython-311.pyc
--index 2dc5d41..6fea675 100644
--Binary files a/app/utils/__pycache__/logger_utils.cpython-311.pyc and b/app/utils/__pycache__/logger_utils.cpython-311.pyc differ
--diff --git a/app/utils/file_utils.py b/app/utils/file_utils.py
--index d35f9e3..da9253d 100644
----- a/app/utils/file_utils.py
--+++ b/app/utils/file_utils.py
--@@ -1,85 +1,97 @@
---import fitz  # PyMuPDF
--+import base64
-- from pathlib import Path
-- 
--+import fitz  # PyMuPDF
--+
-- from app.utils.logger_utils import Logger
-- 
-- logger = Logger.setup_logging().getChild("file_converter")
-- 
-- 
-- class FileConverter:
---	@staticmethod
---	def convert_pdf_to_image_list(
---			full_pdf_file_path: str,
---			output_folder: Path,
---			base_filename_prefix: str
---	) -> list[Path]:
---		"""
---	    Converts a PDF into PNG images, one per page, using PyMuPDF.
---
---	    All images are stored in the given output folder, with filenames
---	    that start with the base UUID to match the original PDF.
---
---	    :param full_pdf_file_path: full path to the saved PDF
---	    :param output_folder: folder to save images into
---	    :param base_filename_prefix: shared prefix (usually the UUID)
---	    :return: list of image file paths as forward-slash strings
---		"""
---
---		logger.info(
---			f"Starting PDF to image conversion for: {full_pdf_file_path}")
---
---		try:
---			# Open the PDF using PyMuPDF
---			pdf_document = fitz.open(full_pdf_file_path)
---		except Exception as error:
---			logger.exception(f"Failed to open PDF document:"
---							 f"{full_pdf_file_path} error: {error}")
---			raise
---		# Collect each generated image path here
---		converted_image_path_list: list[Path] = []
---		total_pages = len(pdf_document)
---		logger.info(f"PDF has opened successfully, total pages: {total_pages}")
---
---		for page_index in range(total_pages):
---			try:
---				logger.info(f"Rendering page {page_index + 1}/{total_pages}")
---				# Load a single page from the PDF
---				pdf_page = pdf_document[page_index]
---
---				# Calculate scaling for desired PDI
---				desired_dpi: int = 300
---				# Use a zoom factor to control the DPI of the output image
---				# The default DPI for PyMuPDF is 72, so we scale accordingly
---				zoom: float = desired_dpi / 72
---				scaling_matrix = fitz.Matrix(zoom, zoom)
---				# Render the page into a pixel-based image(pixmap)
---				page_pixmap = pdf_page.get_pixmap(  # noqa
---					matrix = scaling_matrix)
---
---				# Generate a unique image file name for each page
---				image_filename = (
---					f"{base_filename_prefix}._page_{page_index + 1}.png"
---				)
---				# Save path of the image
---				image_file_path: Path = output_folder / image_filename
---
---				# Save the image to disk
---				page_pixmap.save(str(image_file_path))
---
---				# Add the image path(as a string( to our result list
---				converted_image_path_list.append(
---					str(image_file_path.as_posix()))  # noqa
---
---				logger.info(
---					f"Saved page {page_index + 1} as image: "
---					f"{image_file_path}")
---			except Exception as page_error:
---				logger.exception(
---					f"Error converting page {page_index + 1}"
---					f"{full_pdf_file_path}: {page_error}"
---				)
---
---		# Free the memory used by the PDF
---		pdf_document.close()
---
---		return converted_image_path_list
--+    @staticmethod
--+    def convert_pdf_to_image_list(
--+        full_pdf_file_path: Path,
--+        output_folder: Path,
--+        base_filename_prefix: str
--+    ) -> list[Path]:
--+        """
--+    Converts a PDF into PNG images, one per page, using PyMuPDF.
--+
--+    All images are stored in the given output folder, with filenames
--+    that start with the base UUID to match the original PDF.
--+
--+    :param full_pdf_file_path: full path to the saved PDF
--+    :param output_folder: folder to save images into
--+    :param base_filename_prefix: shared prefix (usually the UUID)
--+    :return: list of image file paths as forward-slash strings
--+        """
--+
--+        logger.info(
--+            f"Starting PDF to image conversion for: {full_pdf_file_path}")
--+
--+        try:
--+            # Open the PDF using PyMuPDF
--+            pdf_document = fitz.open(full_pdf_file_path)
--+        except Exception as error:
--+            logger.exception(f"Failed to open PDF document:"
--+                             f"{full_pdf_file_path} error: {error}")
--+            raise
--+        # Collect each generated image path here
--+        converted_image_path_list: list[Path] = []
--+        total_pages: int = len(pdf_document)
--+        logger.info(f"PDF has opened successfully, total pages: {total_pages}")
--+
--+        for page_index in range(total_pages):
--+            try:
--+                logger.info(f"Rendering page {page_index + 1}/{total_pages}")
--+                # Load a single page from the PDF
--+                pdf_page = pdf_document[page_index]
--+
--+                # Calculate scaling for desired PDI
--+                desired_dpi: int = 300
--+                # Use a zoom factor to control the DPI of the output image
--+                # The default DPI for PyMuPDF is 72, so we scale accordingly
--+                zoom: float = desired_dpi / 72
--+                scaling_matrix = fitz.Matrix(zoom, zoom)
--+                # Render the page into a pixel-based image(pixmap)
--+                page_pixmap = pdf_page.get_pixmap(  # noqa
--+                        matrix=scaling_matrix)
--+
--+                # Generate a unique image file name for each page
--+                image_filename = (
--+                    f"{base_filename_prefix}._page_{page_index + 1}.png"
--+                )
--+                # Save path of the image
--+                image_file_path: Path = output_folder / image_filename
--+
--+                # Save the image to disk
--+                page_pixmap.save(str(image_file_path))
--+
--+                # Add the image path(as a string( to our result list
--+                converted_image_path_list.append(
--+                    str(image_file_path.as_posix()))  # type: ignore
--+
--+                logger.info(
--+                    f"Saved page {page_index + 1} as image: "
--+                    f"{image_file_path}")
--+            except Exception as page_error:
--+                logger.exception(
--+                    f"Error converting page {page_index + 1}"
--+                    f"{full_pdf_file_path}: {page_error}"
--+                )
--+
--+        # Free the memory used by the PDF
--+        pdf_document.close()
--+
--+        return converted_image_path_list
--+
--+    @staticmethod
--+    def load_prompt_from_file(prompt_path: Path) -> str:
--+        with open(prompt_path, "r", encoding="utf-8") as f:
--+            return f.read()
--+
--+    @staticmethod
--+    def image_to_base64(image_path: Path) -> str:
--+        with open(image_path, "rb") as f:
--+            return base64.b64encode(f.read()).decode()
--diff --git a/changes.diff b/changes.diff
--index 8237dfa..d6305cb 100644
----- a/changes.diff
--+++ b/changes.diff
--@@ -1,864 +0,0 @@
---diff --git a/.DS_Store b/.DS_Store
---index 6eefeb5..961a2a7 100644
---Binary files a/.DS_Store and b/.DS_Store differ
---diff --git a/app/__pycache__/main.cpython-311.pyc b/app/__pycache__/main.cpython-311.pyc
---index 98ecc25..bd7c680 100644
---Binary files a/app/__pycache__/main.cpython-311.pyc and b/app/__pycache__/main.cpython-311.pyc differ
---diff --git a/app/routers/__pycache__/analysis_router.cpython-311.pyc b/app/routers/__pycache__/analysis_router.cpython-311.pyc
---index 005b819..89f0af0 100644
---Binary files a/app/routers/__pycache__/analysis_router.cpython-311.pyc and b/app/routers/__pycache__/analysis_router.cpython-311.pyc differ
---diff --git a/app/services/__pycache__/pdf_analysis_service.cpython-311.pyc b/app/services/__pycache__/pdf_analysis_service.cpython-311.pyc
---index 4d7bfcf..ebaa652 100644
---Binary files a/app/services/__pycache__/pdf_analysis_service.cpython-311.pyc and b/app/services/__pycache__/pdf_analysis_service.cpython-311.pyc differ
---diff --git a/app/services/__pycache__/vision_model_inference_service.cpython-311.pyc b/app/services/__pycache__/vision_model_inference_service.cpython-311.pyc
---index df030a7..8fd310a 100644
---Binary files a/app/services/__pycache__/vision_model_inference_service.cpython-311.pyc and b/app/services/__pycache__/vision_model_inference_service.cpython-311.pyc differ
---diff --git a/app/services/pdf_analysis_service.py b/app/services/pdf_analysis_service.py
---index e6daa5c..5827abb 100644
------ a/app/services/pdf_analysis_service.py
---+++ b/app/services/pdf_analysis_service.py
---@@ -8,87 +8,96 @@ import json
--- from app.utils.file_utils import FileConverter
--- from app.utils.logger_utils import Logger
--- from app.services.vision_model_inference_service import \
----	RemoveVisionInferenceService
---+    RemoveVisionInferenceService
---+from app.services.openai_data_extracting_service import extract_emogramma_from_image
--- 
--- logger = Logger.setup_logging().getChild("pdf_analysis_service")
--- 
--- PDF_UPLOADS_ROOT_DIRECTORY: Path = Path("data/blood_work_pdfs")
----PDF_UPLOADS_ROOT_DIRECTORY.mkdir(parents = True, exist_ok = True)
---+PDF_UPLOADS_ROOT_DIRECTORY.mkdir(parents=True, exist_ok=True)
--- 
--- VISION_SERVER_URL = "http://51.21.18.6:4000"
--- remote_vision_inference_service = RemoveVisionInferenceService(
----	VISION_SERVER_URL)
---+    VISION_SERVER_URL)
--- 
--- 
--- def call_inference_and_save_output(
----		image_path_list: list[Path],
----		upload_folder: Path,
----		pdf_uuid: str
---+    extracted_bloodwork_values: str,
---+    upload_folder: Path,
---+    pdf_uuid: str
--- ) -> None:
----	try:
----		logger.info(f"Running inference on images for UUID {pdf_uuid}...")
---+    try:
---+        logger.info(
---+            f"Running inference using extracted blood work values for UUID {pdf_uuid}...")
--- 
----		loop = asyncio.new_event_loop()
----		asyncio.set_event_loop(loop)
---+        loop = asyncio.new_event_loop()
---+        asyncio.set_event_loop(loop)
--- 
----		model_response: dict[str, str] = loop.run_until_complete(
----			remote_vision_inference_service.run_remote_inference(
----				image_file_paths = image_path_list,
----				model_name = "gemma3:27b"
----			)
----		)
---+        model_response: dict[str, str] = loop.run_until_complete(
---+            remote_vision_inference_service.run_remote_inference(
---+                bloodwork_values=extracted_bloodwork_values,
---+                model_name="gemma3:27b"
---+            )
---+        )
--- 
----		output_data: dict[str, str] = model_response
---+        output_data: dict[str, str] = model_response
--- 
----		model_output_path: Path = upload_folder / "model_output.json"
----		with open(model_output_path, "w", encoding = "utf-8") as f:
----			json.dump(output_data, f, ensure_ascii = False)
---+        model_output_path: Path = upload_folder / "model_output.json"
---+        with open(model_output_path, "w", encoding="utf-8") as f:
---+            json.dump(output_data, f, ensure_ascii=False)
--- 
----		logger.info(f"Model output saved to {model_output_path}")
---+        logger.info(f"Model output saved to {model_output_path}")
--- 
----	except Exception as error:
----		logger.exception(
----			f"Failed to run or save inference for UUID: {pdf_uuid} Error: {error}")
----		raise
---+    except Exception as error:
---+        logger.exception(
---+            f"Failed to run or save inference for UUID: {pdf_uuid} Error: {error}")
---+        raise
--- 
--- 
--- async def analyze_uploaded_pdf_file_background(
----		file: UploadFile,
----		background_tasks: BackgroundTasks
---+    file: UploadFile,
---+    background_tasks: BackgroundTasks
--- ) -> dict[str, str]:
----	try:
----		pdf_uuid: str = str(uuid4())
----		upload_folder: Path = PDF_UPLOADS_ROOT_DIRECTORY / pdf_uuid
----		upload_folder.mkdir(parents = True, exist_ok = True)
----
----		with NamedTemporaryFile(delete = False, suffix = ".pdf") as tmp:
----			content = await file.read()
----			tmp.write(content)
----			tmp_path: Path = Path(tmp.name)
----
----		logger.info(f"Received PDF. Temporary file created at {tmp_path}")
----
----		image_path_list: list[Path] = FileConverter.convert_pdf_to_image_list(
----			str(tmp_path),
----			output_folder = upload_folder,
----			base_filename_prefix = pdf_uuid
----		)
----		logger.info(f"Converted to {len(image_path_list)} image(s)")
----
----		tmp_path.unlink(missing_ok = True)
----
----		background_tasks.add_task(call_inference_and_save_output,
----								  image_path_list, upload_folder, pdf_uuid)
----
----		return {
----			"pdf_uuid": pdf_uuid,
----			"message": "Analisi in corso. Torna più tardi per vedere i risultati."
----		}
----
----	except Exception as error:
----		logger.error(f"Failed to process PDF: {error}")
----		raise HTTPException(status_code = 500,
----							detail = "Errore interno durante l'analisi")
----	finally:
----		if tmp_path.exists():
----			tmp_path.unlink(missing_ok = True)
---+    try:
---+        pdf_uuid: str = str(uuid4())
---+        upload_folder: Path = PDF_UPLOADS_ROOT_DIRECTORY / pdf_uuid
---+        upload_folder.mkdir(parents=True, exist_ok=True)
---+
---+        with NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
---+            content = await file.read()
---+            tmp.write(content)
---+            tmp_path: Path = Path(tmp.name)
---+
---+        logger.info(f"Received PDF. Temporary file created at {tmp_path}")
---+
---+        image_path_list: list[Path] = FileConverter.convert_pdf_to_image_list(
---+            str(tmp_path),
---+            output_folder=upload_folder,
---+            base_filename_prefix=pdf_uuid
---+        )
---+        logger.info(f"Converted to {len(image_path_list)} image(s)")
---+
---+        tmp_path.unlink(missing_ok=True)
---+
---+        extracted_bloodwork_values = extract_emogramma_from_image(
---+            image_path_list)
---+
---+        logger.info("Extracting blood work values via OpenAI API")
---+
---+        background_tasks.add_task(call_inference_and_save_output,
---+                                  extracted_bloodwork_values,
---+                                  upload_folder,
---+                                  pdf_uuid)
---+
---+        return {
---+            "pdf_uuid": pdf_uuid,
---+            "message": "Analisi in corso. Torna più tardi per vedere i risultati."
---+        }
---+
---+    except Exception as error:
---+        logger.error(f"Failed to process PDF: {error}")
---+        raise HTTPException(status_code=500,
---+                            detail="Errore interno durante l'analisi")
---+    finally:
---+        if tmp_path.exists():
---+            tmp_path.unlink(missing_ok=True)
---diff --git a/app/services/prompt.txt b/app/services/prompt.txt
---deleted file mode 100644
---index aee66b8..0000000
------ a/app/services/prompt.txt
---+++ /dev/null
---@@ -1,126 +0,0 @@
----Agisci come un medico veterinario specializzato in ematologia, oncologia e medicina interna con oltre 15 anni di esperienza clinica su CANI e GATTI.
----
----◆ INPUT
----Riceverai uno o più PDF o immagini contenenti referti emato-chimici, biochimici, citologici e/o istologici, scritti in lingua italiana o inglese.
----Questi documenti possono contenere tutti i dati necessari: valori, unità, range di riferimento e referti clinici.
----
----⚠️ Non chiedere conferme iniziali. Se il referto è leggibile, avvia immediatamente l’analisi.
----⚠️ Se alcuni dati risultano illeggibili o assenti, continua comunque l’analisi e inserisci un avviso chiaro nella risposta che indichi quali dati mancano o sono incerti.
----
----◆ COMPITI
----1. Tabella dei parametri
----Trascrivi in tabella:
----
----Parametro
----
----Valore misurato
----
----Unità
----
----Range di riferimento (come riportato)
----
----Evidenziazione:
----
----✅ normale
----
----⚠️ lievemente alterato
----
----❌ gravemente alterato
----
----Se mancano valore/unità/range, lascia la cella vuota e segnala in fondo all’analisi quali campi erano incompleti o non leggibili.
----
----2. Analisi matematica
----Calcola e interpreta:
----
----BUN/Creatinina
----
----Calcio/Fosforo
----
----Neutrofili/Linfociti
----
----Na/K
----
----Albumina/Globuline
----
----Indica anomalie e loro significato clinico.
----
----3. Interpretazione clinica
----Spiega ogni alterazione significativa
----
----Formula almeno 3 diagnosi differenziali con % di confidenza
----
----Verifica se i pattern sono compatibili con:
----
----Anemia rigenerativa/non rigenerativa
----
----Neoplasie
----
----Pancreatite, diabete, insufficienza epatica/renale
----
----FIV/FeLV, sindromi infiammatorie o immunomediate
----
----4. Integrazione con citologia/istologia
----Se sono presenti, interpreta i referti citologici/istologici e integra i dati ematochimici.
----
----Non ignorare referti che menzionano neoplasia, linfoma o mitosi.
----
----5. Classificazione dell’urgenza
----Classifica il caso: EMERGENZA, URGENZA A BREVE, ROUTINE
----
----Giustifica la scelta basandoti su: alterazioni gravi, segni oncologici, citopenie, elettroliti critici.
----
----6. Piano diagnostico
----Suggerisci esami aggiuntivi con:
----
----Priorità (Alta / Media / Bassa)
----
----Invasività (Alta / Media / Bassa)
----
----7. Terapia iniziale/supporto
----Farmaci (mg/kg, via, durata)
----
----Supplementi/diete raccomandate
----
----Supporti (SAMe, fluidoterapia, ecc.)
----
----8. Follow-up
----Quando ripetere esami
----
----Segni clinici da monitorare
----
----Indicazioni prognostiche
----
----9. Educazione al proprietario
----Spiega in < 250 parole:
----
----Cosa significano i risultati
----
----Se la situazione è grave o gestibile
----
----Quali passi fare ora
----
----10. Bandierine rosse
----Segnala parametri critici (es. PLT < 100, WBC < 4, Na < 130, K+ > 6.0)
----
----11. Contesto
----Considera:
----
----Digiuno, stress da trasporto
----
----Farmaci in uso
----
----Età, razza, stagione
----
----12. Fonti rapide
----Es. “IRIS 2023”, “Thrall 2012”, “AAHA 2021 oncology”
----
----13. Disclaimer finale
----Analisi automatica basata su referto. Non sostituisce visita clinica veterinaria. Si consiglia valutazione medica diretta.
----
----◆ LINGUA DI USCITA
----Italiano tecnico ma chiaro, adatto a veterinari.
----
----◆ SE MANCANO DATI
----Non interrompere l’analisi. Procedi con ciò che è disponibile e aggiungi in fondo alla risposta un box tipo:
----
----🔶 Attenzione: Alcuni dati non erano leggibili o assenti: [elenco parametri]. È consigliata una revisione manuale del referto originale per conferma.
---\ No newline at end of file
---diff --git a/app/services/vision_model_inference_service.py b/app/services/vision_model_inference_service.py
---index d70ae3e..8049aa6 100644
------ a/app/services/vision_model_inference_service.py
---+++ b/app/services/vision_model_inference_service.py
---@@ -6,123 +6,121 @@ from app.utils.logger_utils import Logger
--- 
--- logger = Logger.setup_logging().getChild("vision_model_inference_service")
--- 
----prompt_file_path: Path = Path("app/services/prompt.txt")
----with open(prompt_file_path, "r", encoding = "utf-8") as prompt_file:
----	prompt: str = prompt_file.read()
---+prompt_file_path: Path = Path("app/services/diagnostic_prompt.txt")
---+with open(prompt_file_path, "r", encoding="utf-8") as prompt_file:
---+    prompt: str = prompt_file.read()
--- 
--- 
--- def clean_model_response(model_response: dict[str, str]) -> dict[str, str]:
----	"""
----	Cleans up model output by:
----	- Removing ANSI escape sequences
----	- Fixing broken UTF-8 characters
----	- Replacing escaped \n and \t with real newlines and tabs
----	- Normalizing problematic Markdown-breaking characters
----	"""
----
----	try:
----		logger.info(f"Cleaning model response for frontend")
----
----		# Remove ANSI terminal escape sequences
----		ansi_escape_pattern: re.Pattern = re.compile(
----			r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])'
----		)
----
----		# Fix common UTF-8 encoding artifacts
----		replacements: dict[str, str] = {
----			"Âµ": "μ",  # micro symbol
----			"â€“": "–",  # en dash
----			"â€”": "—",  # em dash
----			"â€˜": "‘",  # single quote
----			"â€™": "’",  # single quote
----			"â€œ": "“",  # double quote
----			"â€�": "”",  # double quote
----			"â€¢": "•",  # bullet
----			"â€¦": "…",  # ellipsis
----			"â„¢": "™",  # trademark
----			"âˆ’": "−",  # minus
----			"â€": "\"",  # generic quote
----			"â": "",  # remove unknown remnants
----		}
----
----		for key in model_response:
----			if isinstance(model_response[key], str):
----				cleaned_text: str = ansi_escape_pattern.sub('', model_response[
----					key])
----
----				for bad, good in replacements.items():
----					cleaned_text = cleaned_text.replace(bad, good)
----
----				# Replace escaped characters with real formatting
----				cleaned_text = cleaned_text.replace("\\n", "\n")
----				cleaned_text = cleaned_text.replace("\\t", "\t")
----				cleaned_text = cleaned_text.replace("\\r",
----													"")  # remove carriage returns
----				cleaned_text = cleaned_text.replace("*", "")
----
----				# Normalize stray backslashes that may break Markdown tables
----				cleaned_text = cleaned_text.replace("\\", "")
----
----				# Strip extra whitespace from start/end
----				cleaned_text = cleaned_text.strip()
----
----				model_response[key] = cleaned_text
----
----		logger.info("Model response cleaned successfully")
----
----		return model_response
----
----	except Exception as regex_error:
----		logger.exception(f"Error cleaning ANSI sequences: {regex_error}")
----		raise
---+    """
---+    Cleans up model output by:
---+    - Removing ANSI escape sequences
---+    - Fixing broken UTF-8 characters
---+    - Replacing escaped \n and \t with real newlines and tabs
---+    - Normalizing problematic Markdown-breaking characters
---+    """
---+
---+    try:
---+        logger.info(f"Cleaning model response for frontend")
---+
---+        # Remove ANSI terminal escape sequences
---+        ansi_escape_pattern: re.Pattern = re.compile(
---+            r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])'
---+        )
---+
---+        # Fix common UTF-8 encoding artifacts
---+        replacements: dict[str, str] = {
---+            "Âµ": "μ",  # micro symbol
---+            "â€“": "–",  # en dash
---+            "â€”": "—",  # em dash
---+            "â€˜": "‘",  # single quote
---+            "â€™": "’",  # single quote
---+            "â€œ": "“",  # double quote
---+            "â€�": "”",  # double quote
---+            "â€¢": "•",  # bullet
---+            "â€¦": "…",  # ellipsis
---+            "â„¢": "™",  # trademark
---+            "âˆ’": "−",  # minus
---+            "â€": "\"",  # generic quote
---+            "â": "",  # remove unknown remnants
---+        }
---+
---+        for key in model_response:
---+            if isinstance(model_response[key], str):
---+                cleaned_text: str = ansi_escape_pattern.sub('', model_response[
---+                    key])
---+
---+                for bad, good in replacements.items():
---+                    cleaned_text = cleaned_text.replace(bad, good)
---+
---+                # Replace escaped characters with real formatting
---+                cleaned_text = cleaned_text.replace("\\n", "\n")
---+                cleaned_text = cleaned_text.replace("\\t", "\t")
---+                cleaned_text = cleaned_text.replace("\\r",
---+                                                    "")  # remove carriage returns
---+                cleaned_text = cleaned_text.replace("*", "")
---+
---+                # Normalize stray backslashes that may break Markdown tables
---+                cleaned_text = cleaned_text.replace("\\", "")
---+
---+                # Strip extra whitespace from start/end
---+                cleaned_text = cleaned_text.strip()
---+
---+                model_response[key] = cleaned_text
---+
---+        logger.info("Model response cleaned successfully")
---+
---+        return model_response
---+
---+    except Exception as regex_error:
---+        logger.exception(f"Error cleaning ANSI sequences: {regex_error}")
---+        raise
--- 
--- 
--- class RemoveVisionInferenceService:
----	def __init__(self, inference_server_url: str):
----		self.inference_server_url = inference_server_url
----		self.inference_service_endpoint = \
----			f"{self.inference_server_url}/vision_model_inference/"
----
----	async def run_remote_inference(
----			self, image_file_paths: list[Path],
----			model_name: str = "gemma3:27b",
----			diagnostic_prompt: str = prompt,
----	) -> dict[str, str]:
----		"""
----
----		:param image_file_paths:
----		:param diagnostic_prompt:
----		:param model_name:
----		:return:
----		"""
----		files = [
----			("images", (Path(path).name, open(path, "rb"), "image/png"))
----			for path in image_file_paths]
----		form_fields = {
----			"prompt": diagnostic_prompt,
----			"model_name": model_name
----		}
----
----		logger.info(f"Sending request to inference server: "
----					f"{self.inference_service_endpoint}")
----
----		try:
----			async with httpx.AsyncClient() as client:
----				response = await client.post(
----					url = self.inference_service_endpoint,
----					data = form_fields,
----					files = files,
----					timeout = 300,
----				)
----
----			response.raise_for_status()
----			logger.info("Inference completed successfully on remote server")
----
----			response_dict: dict[str, str] = clean_model_response(
----				response.json())
----
----			return clean_model_response(response_dict)
----		except Exception as remote_inference_error:
----			logger.exception(
----				f"Remote inference failed: {remote_inference_error}")
----			raise
---+    def __init__(self, inference_server_url: str):
---+        self.inference_server_url = inference_server_url
---+        self.inference_service_endpoint = \
---+            f"{self.inference_server_url}/vision_model_inference/"
---+
---+    async def run_remote_inference(
---+        self, bloodwork_values: str,
---+        model_name: str = "gemma3:27b",
---+        diagnostic_prompt: str = prompt,
---+    ) -> dict[str, str]:
---+        """
---+    Run inference using pre-extracted text data
---+
---+    :param extracted_text: Pre-extracted text data from images
---+    :param diagnostic_prompt: Prompt to guide the model
---+    :param model_name: Name of the model to use
---+    :return: Dictionary with inference results
---+        """
---+        form_fields = {
---+            "prompt": diagnostic_prompt,
---+            "model_name": model_name,
---+            "bloodwork_values": bloodwork_values
---+        }
---+
---+        logger.info(f"Sending request to inference server: "
---+                    f"{self.inference_service_endpoint}")
---+
---+        try:
---+            async with httpx.AsyncClient() as client:
---+                response = await client.post(
---+                    url=self.inference_service_endpoint,
---+                    json=form_fields,
---+                    timeout=300,
---+                )
---+
---+            response.raise_for_status()
---+            logger.info("Inference completed successfully on remote server")
---+
---+            response_dict: dict[str, str] = clean_model_response(
---+                response.json())
---+
---+            return response_dict
---+        except Exception as remote_inference_error:
---+            logger.exception(
---+                f"Remote inference failed: {remote_inference_error}")
---+            raise
---diff --git a/app/test_main.http b/app/test_main.http
---deleted file mode 100644
---index a2d81a9..0000000
------ a/app/test_main.http
---+++ /dev/null
---@@ -1,11 +0,0 @@
----# Test your FastAPI endpoints
----
----GET http://127.0.0.1:8000/
----Accept: application/json
----
----###
----
----GET http://127.0.0.1:8000/hello/User
----Accept: application/json
----
----###
---diff --git a/app/utils/__pycache__/ec2_instance_controller.cpython-311.pyc b/app/utils/__pycache__/ec2_instance_controller.cpython-311.pyc
---index cdc9097..6c671ec 100644
---Binary files a/app/utils/__pycache__/ec2_instance_controller.cpython-311.pyc and b/app/utils/__pycache__/ec2_instance_controller.cpython-311.pyc differ
---diff --git a/app/utils/__pycache__/file_utils.cpython-311.pyc b/app/utils/__pycache__/file_utils.cpython-311.pyc
---index 8aa0453..3e28062 100644
---Binary files a/app/utils/__pycache__/file_utils.cpython-311.pyc and b/app/utils/__pycache__/file_utils.cpython-311.pyc differ
---diff --git a/app/utils/__pycache__/logger_utils.cpython-311.pyc b/app/utils/__pycache__/logger_utils.cpython-311.pyc
---index d309677..2dc5d41 100644
---Binary files a/app/utils/__pycache__/logger_utils.cpython-311.pyc and b/app/utils/__pycache__/logger_utils.cpython-311.pyc differ
---diff --git a/changes.diff b/changes.diff
---index d9599a8..2137eb4 100644
---Binary files a/changes.diff and b/changes.diff differ
---diff --git a/cuda_test.py b/cuda_test.py
---deleted file mode 100644
---index c59f0b5..0000000
------ a/cuda_test.py
---+++ /dev/null
---@@ -1,4 +0,0 @@
----import torch
----
----print(torch.cuda.is_available())
----print(torch.cuda.get_device_name())
---diff --git a/data/.DS_Store b/data/.DS_Store
---index e4cd861..becfc94 100644
---Binary files a/data/.DS_Store and b/data/.DS_Store differ
---diff --git a/data/blood_work_pdfs/.DS_Store b/data/blood_work_pdfs/.DS_Store
---index 688e3a0..67c68a2 100644
---Binary files a/data/blood_work_pdfs/.DS_Store and b/data/blood_work_pdfs/.DS_Store differ
---diff --git a/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/15cb51bd-2165-4458-ba1f-c41236c9235a._page_1.png b/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/15cb51bd-2165-4458-ba1f-c41236c9235a._page_1.png
---deleted file mode 100644
---index c12dfc0..0000000
---Binary files a/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/15cb51bd-2165-4458-ba1f-c41236c9235a._page_1.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/15cb51bd-2165-4458-ba1f-c41236c9235a._page_2.png b/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/15cb51bd-2165-4458-ba1f-c41236c9235a._page_2.png
---deleted file mode 100644
---index bd9351e..0000000
---Binary files a/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/15cb51bd-2165-4458-ba1f-c41236c9235a._page_2.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/15cb51bd-2165-4458-ba1f-c41236c9235a._page_3.png b/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/15cb51bd-2165-4458-ba1f-c41236c9235a._page_3.png
---deleted file mode 100644
---index 1eb3eb4..0000000
---Binary files a/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/15cb51bd-2165-4458-ba1f-c41236c9235a._page_3.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/15cb51bd-2165-4458-ba1f-c41236c9235a._page_4.png b/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/15cb51bd-2165-4458-ba1f-c41236c9235a._page_4.png
---deleted file mode 100644
---index 33ae6c5..0000000
---Binary files a/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/15cb51bd-2165-4458-ba1f-c41236c9235a._page_4.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/model_output.json b/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/model_output.json
---deleted file mode 100644
---index 2561279..0000000
------ a/data/blood_work_pdfs/15cb51bd-2165-4458-ba1f-c41236c9235a/model_output.json
---+++ /dev/null
---@@ -1 +0,0 @@
----{"result": "1. Tabella dei parametri\n\n| Parametro | Valore misurato | Unità | Range di riferimento | Evidenziazione |\n| --- | --- | --- | --- | --- |\n| BUN/Creatinina | 20 mg/dL | mg/dL | 15-35 mg/dL | ✅ normale |\n| Calcio/Fosforo | 2.5 mg/dL | mg/dL | 2.0-4.5 mg/dL | ✅ normale |\n| Neutrofili/Linfociti | 70% | % | 60-80% | ✅ normale |\n| Na/K | 135 mEq/L | mEq/L | 130-145 mEq/L | ✅ normale |\n| Albumina/Globuline | 3.5 g/dL | g/dL | 2.8-4.8 g/dL | ✅ normale |\n\n2. Analisi matematica\n\n BUN/Creatinina: Valore all'interno del range di riferimento, quindi normale.\n Calcio/Fosforo: Valore all'interno del range di riferimento, quindi normale.\n Neutrofili/Linfociti: Valore all'interno del range di riferimento, quindi normale.\n Na/K: Valore all'interno del range di riferimento, quindi normale.\n Albumina/Globuline: Valore all'interno del range di riferimento, quindi normale.\n\n3. Interpretazione clinica\n\n Non sono presenti alterazioni significative.\n\n4. Interpretazione citologica/istologica\n\n Non sono presenti referti citologici/istologici da analizzare.\n\n5. Classificazione dell’urgenza\n\n Routine.\n\n6. Piano diagnostico\n\n Esami aggiuntivi:\n\t+ Priorità: Alta\n\t+ Invasività: Media\n Farmaci (mg/kg, via, durata):\n\t+ Supplementi raccomandati: SAMe, fluidoterapia, ecc.\n Supporti (SAMe, fluidoterapia, ecc.):\n\t+ Supplementi raccomandati: SAMe, fluidoterapia, ecc.\n Follow-up:\n\t+ Quando ripetere esami: 3 mesi\n\t+ Segni clinici da monitorare: Peso, comportamento, sintomi di dolore o discomfort.\n\t+ Indicazioni prognostiche: Buona prognosi con monitoraggio periodico.\n Educazione al proprietario:\n\t+ Cosa significano i risultati: I valori sono all'interno del range di riferimento, quindi normale.\n\t+ Se la situazione è grave o gestibile: La situazione è buona e non ci sono segni di emergenza o urgenza.\n\t+ Quali passi fare ora: Continuare a monitorare il cane con esami periodici e seguire le indicazioni del veterinario.\n Bandierine rosse:\n\t+ PLT < 100, WBC < 4, Na < 130, K+ > 6.0: Non presenti.\n Contesto:\n\t+ Digiuno, stress da trasporto: Non presenti.\n\t+ Farmaci in uso: Non presenti.\n\t+ Età, razza, stagione: Non presenti.\n Fonti rapide:\n\t+ IRIS 2023, Thrall 2012, AAHA 2021 oncology: Non presenti.\n Disclaimer finale:\n\t+ Analisi automatica basata su referto. Non sostituisce visita clinica veterinaria. Si consiglia valutazione medica diretta."}
---\ No newline at end of file
---diff --git a/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/28ded63e-ffed-47b4-a143-95f0812561ee._page_1.png b/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/28ded63e-ffed-47b4-a143-95f0812561ee._page_1.png
---deleted file mode 100644
---index c12dfc0..0000000
---Binary files a/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/28ded63e-ffed-47b4-a143-95f0812561ee._page_1.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/28ded63e-ffed-47b4-a143-95f0812561ee._page_2.png b/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/28ded63e-ffed-47b4-a143-95f0812561ee._page_2.png
---deleted file mode 100644
---index bd9351e..0000000
---Binary files a/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/28ded63e-ffed-47b4-a143-95f0812561ee._page_2.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/28ded63e-ffed-47b4-a143-95f0812561ee._page_3.png b/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/28ded63e-ffed-47b4-a143-95f0812561ee._page_3.png
---deleted file mode 100644
---index 1eb3eb4..0000000
---Binary files a/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/28ded63e-ffed-47b4-a143-95f0812561ee._page_3.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/28ded63e-ffed-47b4-a143-95f0812561ee._page_4.png b/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/28ded63e-ffed-47b4-a143-95f0812561ee._page_4.png
---deleted file mode 100644
---index 33ae6c5..0000000
---Binary files a/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/28ded63e-ffed-47b4-a143-95f0812561ee._page_4.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/model_output.json b/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/model_output.json
---deleted file mode 100644
---index 932dcbb..0000000
------ a/data/blood_work_pdfs/28ded63e-ffed-47b4-a143-95f0812561ee/model_output.json
---+++ /dev/null
---@@ -1 +0,0 @@
----{"result": "1. Tabella dei parametri\n\n| Parametro | Valore misurato | Unità | Range di riferimento | Evidenziazione |\n| --- | --- | --- | --- | --- |\n| BUN/Creatinina | 20 mg/dL | mg/dL | 15-30 mg/dL | ✅ normale |\n| Calcio/Fosforo | 2.5 mg/dL | mg/dL | 2.0-4.0 mg/dL | ✅ normale |\n| Neutrofili/Linfociti | 70% | % | 60-80% | ✅ normale |\n| Na/K | 150 mEq/L | mEq/L | 140-160 mEq/L | ✅ normale |\n| Albumina/Globuline | 3.5 g/dL | g/dL | 3.0-4.5 g/dL | ✅ normale |\n\n2. Analisi matematica\n\n BUN/Creatinina: Valore all'interno del range di riferimento, quindi normale.\n Calcio/Fosforo: Valore all'interno del range di riferimento, quindi normale.\n Neutrofili/Linfociti: Valore all'interno del range di riferimento, quindi normale.\n Na/K: Valore all'interno del range di riferimento, quindi normale.\n Albumina/Globuline: Valore all'interno del range di riferimento, quindi normale.\n\n3. Interpretazione clinica\n\n Non sono presenti alterazioni significative.\n\n4. Interpretazione citologico-istologica\n\n Non sono presenti referti citologici o istologici.\n\n5. Classificazione dell'urgenza\n\n Routine.\n\n6. Piano diagnostico\n\n Esami aggiuntivi:\n\t+ Priorità: Alta\n\t+ Invasività: Media\n Farmaci (mg/kg, via, durata): Non sono presenti informazioni su farmaci in uso.\n Supplementi/diete raccomandate: Non sono presenti informazioni su supplementi o dietas raccomandate.\n Follow-up:\n\t+ Quando ripetere esami: In base alla situazione clinica del cane, ad esempio in caso di alterazioni significative o se ci sono segni oncologici.\n\t+ Segni clinici da monitorare: In base alla situazione clinica del cane, ad esempio in caso di alterazioni significative o se ci sono segni oncologici.\n\t+ Indicazioni prognostiche: Non sono presenti informazioni su indicazioni prognostiche.\n Educazione al proprietario:\n\t+ Cosa significano i risultati: I risultati indicano che il cane è in buone condizioni e non ci sono alterazioni significative.\n\t+ Se la situazione è grave o gestibile: Non ci sono alterazioni significative, quindi la situazione del cane è gestibile.\n\t+ Quali passi fare ora: In base alla situazione clinica del cane, ad esempio in caso di alterazioni significative o se ci sono segni oncologici.\n Bandierine rosse: Non ci sono parametri critici da segnalare.\n Contesto:\n\t+ Digiuno, stress da trasporto: Non ci sono informazioni su questi fattori.\n\t+ Farmaci in uso: Non ci sono informazioni su farmaci in uso.\n\t+ Età, razza, stagione: Non ci sono informazioni su questi fattori.\n Fonti rapide: Non ci sono fonti rapide da segnalare.\n Disclaimer finale: Analisi automatica basata su referto. Non sostituisce visita clinica veterinaria. Si consiglia valutazione medica diretta."}
---\ No newline at end of file
---diff --git a/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/39f3edf9-8ef5-4b6d-9aac-2891647b677a._page_1.png b/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/39f3edf9-8ef5-4b6d-9aac-2891647b677a._page_1.png
---deleted file mode 100644
---index c12dfc0..0000000
---Binary files a/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/39f3edf9-8ef5-4b6d-9aac-2891647b677a._page_1.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/39f3edf9-8ef5-4b6d-9aac-2891647b677a._page_2.png b/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/39f3edf9-8ef5-4b6d-9aac-2891647b677a._page_2.png
---deleted file mode 100644
---index bd9351e..0000000
---Binary files a/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/39f3edf9-8ef5-4b6d-9aac-2891647b677a._page_2.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/39f3edf9-8ef5-4b6d-9aac-2891647b677a._page_3.png b/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/39f3edf9-8ef5-4b6d-9aac-2891647b677a._page_3.png
---deleted file mode 100644
---index 1eb3eb4..0000000
---Binary files a/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/39f3edf9-8ef5-4b6d-9aac-2891647b677a._page_3.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/39f3edf9-8ef5-4b6d-9aac-2891647b677a._page_4.png b/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/39f3edf9-8ef5-4b6d-9aac-2891647b677a._page_4.png
---deleted file mode 100644
---index 33ae6c5..0000000
---Binary files a/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/39f3edf9-8ef5-4b6d-9aac-2891647b677a._page_4.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/model_output.json b/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/model_output.json
---deleted file mode 100644
---index 363f136..0000000
------ a/data/blood_work_pdfs/39f3edf9-8ef5-4b6d-9aac-2891647b677a/model_output.json
---+++ /dev/null
---@@ -1 +0,0 @@
----{"result": "1. Tabella dei parametri\n\n| Parametro | Valore misurato | Unità | Range di riferimento | Evidenziazione |\n| --- | --- | --- | --- | --- |\n| BUN/Creatinina | 20 mg/dL | mg/dL | 15-30 mg/dL | ✅ normale |\n| Calcio/Fosforo | 2.5 mmol/L | mmol/L | 2.0-4.0 mmol/L | ✅ normale |\n| Neutrofili/Linfociti | 70% | % | 60-80% | ✅ normale |\n| Na/K | 135 mEq/L | mEq/L | 130-145 mEq/L | ✅ normale |\n| Albumina/Globuline | 3.5 g/dL | g/dL | 3.0-4.5 g/dL | ✅ normale |\n\n2. Analisi matematica\n\n BUN/Creatinina: Valore all'interno del range di riferimento, quindi normale.\n Calcio/Fosforo: Valore all'interno del range di riferimento, quindi normale.\n Neutrofili/Linfociti: Valore all'interno del range di riferimento, quindi normale.\n Na/K: Valore all'interno del range di riferimento, quindi normale.\n Albumina/Globuline: Valore all'interno del range di riferimento, quindi normale.\n\n3. Interpretazione clinica\n\n Non sono presenti alterazioni significative.\n\n4. Interpretazione citologica/istologica\n\n Non sono presenti referti citologici/istologici.\n\n5. Classificazione dell’urgenza\n\n Routine.\n\n6. Piano diagnostico\n\n Esami aggiuntivi:\n\t+ Priorità: Alta\n\t+ Invasività: Media\n Farmaci (mg/kg, via, durata):\n\t+ Supplementi raccomandati: SAMe, fluidoterapia, ecc.\n Supporti (SAMe, fluidoterapia, ecc.):\n\t+ Fluidoterapia\n Follow-up:\n\t+ Quando ripetere esami: 1 mese\n\t+ Segni clinici da monitorare: Peso, comportamento, sintomi di dolore o discomfort\n\t+ Indicazioni prognostiche: Monitoraggio periodico del peso e del comportamento.\n Educazione al proprietario:\n\t+ I risultati indicano che il cane è in buone condizioni. Se la situazione è grave o gestibile, si consiglia una visita clinica veterinaria per un'analisi più approfondita e per un piano di trattamento personalizzato.\n Bandierine rosse:\n\t+ PLT < 100: Non presente\n\t+ WBC < 4: Non presente\n\t+ Na < 130: Non presente\n\t+ K+ > 6.0: Non presente\n Contesto:\n\t+ Digiuno, stress da trasporto: Non presente\n\t+ Farmaci in uso: Non presente\n\t+ Età, razza, stagione: Non presente\n\t+ Fonti rapide: Non presente\n Disclaimer finale:\n\t+ Analisi automatica basata su referto. Non sostituisce visita clinica veterinaria. Si consiglia valutazione medica diretta."}
---\ No newline at end of file
---diff --git a/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/49bc2b07-81b1-456d-b74a-8fc316315590._page_1.png b/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/49bc2b07-81b1-456d-b74a-8fc316315590._page_1.png
---deleted file mode 100644
---index c12dfc0..0000000
---Binary files a/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/49bc2b07-81b1-456d-b74a-8fc316315590._page_1.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/49bc2b07-81b1-456d-b74a-8fc316315590._page_2.png b/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/49bc2b07-81b1-456d-b74a-8fc316315590._page_2.png
---deleted file mode 100644
---index bd9351e..0000000
---Binary files a/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/49bc2b07-81b1-456d-b74a-8fc316315590._page_2.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/49bc2b07-81b1-456d-b74a-8fc316315590._page_3.png b/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/49bc2b07-81b1-456d-b74a-8fc316315590._page_3.png
---deleted file mode 100644
---index 1eb3eb4..0000000
---Binary files a/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/49bc2b07-81b1-456d-b74a-8fc316315590._page_3.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/49bc2b07-81b1-456d-b74a-8fc316315590._page_4.png b/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/49bc2b07-81b1-456d-b74a-8fc316315590._page_4.png
---deleted file mode 100644
---index 33ae6c5..0000000
---Binary files a/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/49bc2b07-81b1-456d-b74a-8fc316315590._page_4.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/model_output.json b/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/model_output.json
---deleted file mode 100644
---index 3e80cb1..0000000
------ a/data/blood_work_pdfs/49bc2b07-81b1-456d-b74a-8fc316315590/model_output.json
---+++ /dev/null
---@@ -1 +0,0 @@
----{"result": "1. Tabella dei parametri\n\n| Parametro | Valore misurato | Unità | Range di riferimento | Evidenziazione |\n| --- | --- | --- | --- | --- |\n| BUN/Creatinina | 20 mg/dL | mg/dL | 15-35 mg/dL | ✅ normale |\n| Calcio/Fosforo | 2.5 mg/dL | mg/dL | 2.0-4.5 mg/dL | ✅ normale |\n| Neutrofili/Linfociti | 70% | % | 60-80% | ✅ normale |\n| Na/K | 135 mEq/L | mEq/L | 130-145 mEq/L | ✅ normale |\n| Albumina/Globuline | 3.5 g/dL | g/dL | 2.8-4.8 g/dL | ✅ normale |\n\n2. Analisi matematica\n\n BUN/Creatinina: Valore all'interno del range di riferimento, quindi normale.\n Calcio/Fosforo: Valore all'interno del range di riferimento, quindi normale.\n Neutrofili/Linfociti: Valore all'interno del range di riferimento, quindi normale.\n Na/K: Valore all'interno del range di riferimento, quindi normale.\n Albumina/Globuline: Valore all'interno del range di riferimento, quindi normale.\n\n3. Interpretazione clinica\n\n Non sono presenti alterazioni significative.\n\n4. Interpretazione citologica/istologica\n\n Non sono presenti referti citologici o istologici.\n\n5. Classificazione dell'urgenza\n\n Routine.\n\n6. Piano diagnostico\n\n Esami aggiuntivi:\n\t+ Priorità: Alta\n\t+ Invasività: Media\n Farmaci (mg/kg, via, durata):\n\t+ Supplementi raccomandati: SAMe, fluidoterapia, ecc.\n Supporti (SAMe, fluidoterapia, ecc.):\n\t+ Supplementi raccomandati: SAMe, fluidoterapia, ecc.\n Follow-up:\n\t+ Quando ripetere esami: 3 mesi\n\t+ Segni clinici da monitorare: Peso, comportamento, sintomi di dolore o discomfort.\n\t+ Indicazioni prognostiche: Buona prognosi con monitoraggio periodico.\n Educazione al proprietario:\n\t+ Cosa significano i risultati: I valori sono all'interno del range di riferimento, quindi normale.\n\t+ Se la situazione è grave o gestibile: La situazione è buona e non ci sono segni di emergenza o urgenza.\n\t+ Quali passi fare ora: Continuare a monitorare i valori ematochimici periodiciamente e seguire le indicazioni del veterinario.\n Bandierine rosse:\n\t+ PLT < 100, WBC < 4, Na < 130, K+ > 6.0: Non presenti.\n Contesto:\n\t+ Digiuno, stress da trasporto: Non presenti.\n\t+ Farmaci in uso: Non presenti.\n\t+ Età, razza, stagione: Non presenti.\n Fonti rapide:\n\t+ IRIS 2023, Thrall 2012, AAHA 2021 oncology: Non presenti.\n Disclaimer finale:\n\t+ Analisi automatica basata su referto. Non sostituisce visita clinica veterinaria. Si consiglia valutazione medica diretta."}
---\ No newline at end of file
---diff --git a/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/76423b77-4169-40fd-ac3a-cbb922481f9a._page_1.png b/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/76423b77-4169-40fd-ac3a-cbb922481f9a._page_1.png
---deleted file mode 100644
---index c12dfc0..0000000
---Binary files a/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/76423b77-4169-40fd-ac3a-cbb922481f9a._page_1.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/76423b77-4169-40fd-ac3a-cbb922481f9a._page_2.png b/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/76423b77-4169-40fd-ac3a-cbb922481f9a._page_2.png
---deleted file mode 100644
---index bd9351e..0000000
---Binary files a/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/76423b77-4169-40fd-ac3a-cbb922481f9a._page_2.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/76423b77-4169-40fd-ac3a-cbb922481f9a._page_3.png b/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/76423b77-4169-40fd-ac3a-cbb922481f9a._page_3.png
---deleted file mode 100644
---index 1eb3eb4..0000000
---Binary files a/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/76423b77-4169-40fd-ac3a-cbb922481f9a._page_3.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/76423b77-4169-40fd-ac3a-cbb922481f9a._page_4.png b/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/76423b77-4169-40fd-ac3a-cbb922481f9a._page_4.png
---deleted file mode 100644
---index 33ae6c5..0000000
---Binary files a/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/76423b77-4169-40fd-ac3a-cbb922481f9a._page_4.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/model_output.json b/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/model_output.json
---deleted file mode 100644
---index 79d24d0..0000000
------ a/data/blood_work_pdfs/76423b77-4169-40fd-ac3a-cbb922481f9a/model_output.json
---+++ /dev/null
---@@ -1 +0,0 @@
----{"result": "1. Tabella dei parametri\n\n| Parametro | Valore misurato | Unità | Range di riferimento | Evidenziazione |\n| --- | --- | --- | --- | --- |\n| BUN/Creatinina | 20 mg/dL | mg/dL | 15-35 mg/dL | ✅ normale |\n| Calcio/Fosforo | 2.5 mmol/L | mmol/L | 2.0-4.5 mmol/L | ✅ normale |\n| Neutrofili/Linfociti | 70% | % | 60-80% | ✅ normale |\n| Na/K | 135 mEq/L | mEq/L | 130-145 mEq/L | ✅ normale |\n| Albumina/Globuline | 3.5 g/dL | g/dL | 2.8-5.2 g/dL | ✅ normale |\n\n2. Analisi matematica\n\n BUN/Creatinina: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n Calcio/Fosforo: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n Neutrofili/Linfociti: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n Na/K: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n Albumina/Globuline: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n\n3. Interpretazione clinica\n\nNon ci sono alterazioni significative.\n\n4. Integrazione con citologia/istologia\n\nNon ci sono referti citologici o istologici disponibili per l'analisi.\n\n5. Classificazione dell’urgenza\n\nRoutine.\n\n6. Piano diagnostico\n\n Priorità: Bassa\n Invasività: Bassa\n Farmaci (mg/kg, via, durata): Non disponibili\n Supplementi/diete raccomandate: Non disponibili\n Supporti (SAMe, fluidoterapia, ecc.): Non disponibili\n Follow-up: Non disponibili\n Educazione al proprietario: Non disponibili\n Bandierine rosse: Non disponibili\n Contesto: Non disponibili\n Fonti rapide: Non disponibili\n Disclaimer finale: Analisi automatica basata su referto. Non sostituisce visita clinica veterinaria. Si consiglia valutazione medica diretta."}
---\ No newline at end of file
---diff --git a/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/ae838344-c706-4847-bc68-9adea1ff78c2._page_1.png b/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/ae838344-c706-4847-bc68-9adea1ff78c2._page_1.png
---deleted file mode 100644
---index c12dfc0..0000000
---Binary files a/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/ae838344-c706-4847-bc68-9adea1ff78c2._page_1.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/ae838344-c706-4847-bc68-9adea1ff78c2._page_2.png b/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/ae838344-c706-4847-bc68-9adea1ff78c2._page_2.png
---deleted file mode 100644
---index bd9351e..0000000
---Binary files a/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/ae838344-c706-4847-bc68-9adea1ff78c2._page_2.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/ae838344-c706-4847-bc68-9adea1ff78c2._page_3.png b/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/ae838344-c706-4847-bc68-9adea1ff78c2._page_3.png
---deleted file mode 100644
---index 1eb3eb4..0000000
---Binary files a/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/ae838344-c706-4847-bc68-9adea1ff78c2._page_3.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/ae838344-c706-4847-bc68-9adea1ff78c2._page_4.png b/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/ae838344-c706-4847-bc68-9adea1ff78c2._page_4.png
---deleted file mode 100644
---index 33ae6c5..0000000
---Binary files a/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/ae838344-c706-4847-bc68-9adea1ff78c2._page_4.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/model_output.json b/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/model_output.json
---deleted file mode 100644
---index a6b6d40..0000000
------ a/data/blood_work_pdfs/ae838344-c706-4847-bc68-9adea1ff78c2/model_output.json
---+++ /dev/null
---@@ -1 +0,0 @@
----{"result": "1. Tabella dei parametri\n\n| Parametro | Valore misurato | Unità | Range di riferimento | Evidenziazione |\n| --- | --- | --- | --- | --- |\n| BUN/Creatinina | 20 mg/dL | mg/dL | 15-30 mg/dL | ✅ normale |\n| Calcio/Fosforo | 2.5 mg/dL | mg/dL | 2.0-4.0 mg/dL | ✅ normale |\n| Neutrofili/Linfociti | 70% | % | 60-80% | ✅ normale |\n| Na/K | 150 mEq/L | mEq/L | 140-160 mEq/L | ✅ normale |\n| Albumina/Globuline | 3.5 g/dL | g/dL | 3.0-4.5 g/dL | ✅ normale |\n\n2. Analisi matematica\n\n BUN/Creatinina: Valore all'interno del range di riferimento, quindi normale.\n Calcio/Fosforo: Valore all'interno del range di riferimento, quindi normale.\n Neutrofili/Linfociti: Valore all'interno del range di riferimento, quindi normale.\n Na/K: Valore all'interno del range di riferimento, quindi normale.\n Albumina/Globuline: Valore all'interno del range di riferimento, quindi normale.\n\n3. Interpretazione clinica\n\n Non sono presenti alterazioni significative.\n\n4. Interpretazione citologico-istologica\n\n Non sono presenti referti citologici o istologici.\n\n5. Classificazione dell'urgenza\n\n Routine.\n\n6. Piano diagnostico\n\n Esami aggiuntivi:\n\t+ Priorità: Alta\n\t+ Invasività: Media\n Farmaci (mg/kg, via, durata): Non sono stati utilizzati farmaci specifici per questo caso.\n Supplementi/diete raccomandate: Non sono stati utilizzati supplementi o diete specifici per questo caso.\n Supporti (SAMe, fluidoterapia, ecc.): Non sono stati utilizzati supporti specifici per questo caso.\n Follow-up: Ripetere esami in 1 mese. Segni clinici da monitorare: Peso, comportamento, sintomi di dolore o discomfort. Indicazioni prognostiche: Non sono stati utilizzati indicatori prognostici specifici per questo caso.\n Educazione al proprietario:\n\t+ I risultati indicano che il cane è in buone condizioni e non ci sono segni di gravità o gestione urgente.\n\t+ Si consiglia di continuare a monitorare il cane e di seguire le indicazioni del veterinario.\n Bandierine rosse: Non ci sono parametri critici da segnalare.\n Contesto:\n\t+ Il cane è in buone condizioni e non ci sono segni di digiuno, stress da trasporto o farmaci in uso che possano influire sui risultati ematochimici.\n\t+ Non ci sono informazioni specifiche sull'età, razza o stagione.\n Fonti rapide: Non ci sono fonti rapide utilizzate per questo caso.\n Disclaimer finale: Analisi automatica basata su referto. Non sostituisce visita clinica veterinaria. Si consiglia valutazione medica diretta."}
---\ No newline at end of file
---diff --git a/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/b2a6a985-155d-4852-92ea-9bfaa953b878._page_1.png b/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/b2a6a985-155d-4852-92ea-9bfaa953b878._page_1.png
---deleted file mode 100644
---index c12dfc0..0000000
---Binary files a/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/b2a6a985-155d-4852-92ea-9bfaa953b878._page_1.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/b2a6a985-155d-4852-92ea-9bfaa953b878._page_2.png b/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/b2a6a985-155d-4852-92ea-9bfaa953b878._page_2.png
---deleted file mode 100644
---index bd9351e..0000000
---Binary files a/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/b2a6a985-155d-4852-92ea-9bfaa953b878._page_2.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/b2a6a985-155d-4852-92ea-9bfaa953b878._page_3.png b/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/b2a6a985-155d-4852-92ea-9bfaa953b878._page_3.png
---deleted file mode 100644
---index 1eb3eb4..0000000
---Binary files a/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/b2a6a985-155d-4852-92ea-9bfaa953b878._page_3.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/b2a6a985-155d-4852-92ea-9bfaa953b878._page_4.png b/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/b2a6a985-155d-4852-92ea-9bfaa953b878._page_4.png
---deleted file mode 100644
---index 33ae6c5..0000000
---Binary files a/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/b2a6a985-155d-4852-92ea-9bfaa953b878._page_4.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/model_output.json b/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/model_output.json
---deleted file mode 100644
---index abc281f..0000000
------ a/data/blood_work_pdfs/b2a6a985-155d-4852-92ea-9bfaa953b878/model_output.json
---+++ /dev/null
---@@ -1 +0,0 @@
----{"result": "1. Tabella dei parametri\n\n| Parametro | Valore misurato | Unità | Range di riferimento | Evidenziazione |\n| --- | --- | --- | --- | --- |\n| BUN/Creatinina | 20 mg/dL | mg/dL | 15-30 mg/dL | ✅ normale |\n| Calcio/Fosforo | 2.5 mmol/L | mmol/L | 2.0-4.0 mmol/L | ✅ normale |\n| Neutrofili/Linfociti | 70% | % | 60-80% | ✅ normale |\n| Na/K | 135 mEq/L | mEq/L | 130-145 mEq/L | ✅ normale |\n| Albumina/Globuline | 3.5 g/dL | g/dL | 3.0-4.5 g/dL | ✅ normale |\n\n2. Analisi matematica\n\n BUN/Creatinina: Valore all'interno del range di riferimento, quindi normale.\n Calcio/Fosforo: Valore all'interno del range di riferimento, quindi normale.\n Neutrofili/Linfociti: Valore all'interno del range di riferimento, quindi normale.\n Na/K: Valore all'interno del range di riferimento, quindi normale.\n Albumina/Globuline: Valore all'interno del range di riferimento, quindi normale.\n\n3. Interpretazione clinica\n\n Non sono presenti alterazioni significative che indichino una patologia ematochimica o oncologica.\n La situazione è compatibile con un quadro di salute generale e non ci sono segni di anemia rigenerativa, neoplasie, pancreatite, diabete, insufficienza epatica/renale, FIV/FeLV, sindromi infiammatorie o immunomediate.\n\n4. Integrazione con citologia/istologia\n\n Non sono presenti referti citologici o istologici che menzionano neoplasia, linfoma o mitosi.\n\n5. Classificazione dell’urgenza\n\n La situazione è compatibile con una routine diagnostico.\n\n6. Piano diagnostico\n\n Non sono presenti dati per suggerire esami aggiuntivi.\n\n7. Terapia iniziale/supporto\n\n Non sono presenti informazioni su farmaci, supplementi o dietete raccomandate.\n\n8. Follow-up\n\n Non sono presenti indicazioni per ripetere esami.\n\n9. Educazione al proprietario\n\n I risultati indicano un quadro di salute generale e non ci sono segni di patologie ematochimiche o oncologiche. Se la situazione è grave o gestibile, si consiglia una visita clinica veterinaria per valutare il caso in modo approfondito.\n\n10. Bandierine rosse\n\n Non ci sono parametri critici da segnalare.\n\n11. Contesto\n\n Non ci sono dati per considerare digiuno, stress da trasporto, farmaci in uso, età, razza o stagione.\n\n12. Fonti rapide\n\n Non ci sono fonti rapide da segnalare.\n\n13. Disclaimer finale\n\n L'analisi automatica basata su referto non sostituisce una visita clinica veterinaria. Si consiglia valutazione medica diretta per un quadro di salute generale e non ci sono segni di patologie ematochimiche o oncologiche."}
---\ No newline at end of file
---diff --git a/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/b43f3b5e-8086-4674-a13f-78f3192a1fa4._page_1.png b/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/b43f3b5e-8086-4674-a13f-78f3192a1fa4._page_1.png
---deleted file mode 100644
---index c12dfc0..0000000
---Binary files a/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/b43f3b5e-8086-4674-a13f-78f3192a1fa4._page_1.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/b43f3b5e-8086-4674-a13f-78f3192a1fa4._page_2.png b/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/b43f3b5e-8086-4674-a13f-78f3192a1fa4._page_2.png
---deleted file mode 100644
---index bd9351e..0000000
---Binary files a/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/b43f3b5e-8086-4674-a13f-78f3192a1fa4._page_2.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/b43f3b5e-8086-4674-a13f-78f3192a1fa4._page_3.png b/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/b43f3b5e-8086-4674-a13f-78f3192a1fa4._page_3.png
---deleted file mode 100644
---index 1eb3eb4..0000000
---Binary files a/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/b43f3b5e-8086-4674-a13f-78f3192a1fa4._page_3.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/b43f3b5e-8086-4674-a13f-78f3192a1fa4._page_4.png b/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/b43f3b5e-8086-4674-a13f-78f3192a1fa4._page_4.png
---deleted file mode 100644
---index 33ae6c5..0000000
---Binary files a/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/b43f3b5e-8086-4674-a13f-78f3192a1fa4._page_4.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/model_output.json b/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/model_output.json
---deleted file mode 100644
---index 39fe8da..0000000
------ a/data/blood_work_pdfs/b43f3b5e-8086-4674-a13f-78f3192a1fa4/model_output.json
---+++ /dev/null
---@@ -1 +0,0 @@
----{"result": "1. Tabella dei parametri\n\n| Parametro | Valore misurato | Unità | Range di riferimento | Evidenziazione |\n| --- | --- | --- | --- | --- |\n| BUN/Creatinina | 20 mg/dL | mg/dL | 15-30 mg/dL | ✅ normale |\n| Calcio/Fosforo | 2.5 mmol/L | mmol/L | 2.0-4.0 mmol/L | ✅ normale |\n| Neutrofili/Linfociti | 70% | % | 60-80% | ✅ normale |\n| Na/K | 150 mEq/L | mEq/L | 140-160 mEq/L | ✅ normale |\n| Albumina/Globuline | 3.5 g/dL | g/dL | 3.0-4.5 g/dL | ✅ normale |\n\n2. Analisi matematica\n\n BUN/Creatinina: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n Calcio/Fosforo: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n Neutrofili/Linfociti: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n Na/K: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n Albumina/Globuline: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n\n3. Interpretazione clinica\n\nNon sono presenti alterazioni significative.\n\n4. Integrazione con citologia/istologia\n\nNon sono presenti referti citologici o istologici.\n\n5. Classificazione dell’urgenza\n\nRoutine.\n\n6. Piano diagnostico\n\n Priorità: Bassa\n Invasività: Bassa\n Farmaci (mg/kg, via, durata): Non sono presenti informazioni su farmaci in uso.\n Supplementi/diete raccomandate: Non sono presenti informazioni su supplementi o diete raccomandate.\n Supporti (SAMe, fluidoterapia, ecc.): Non sono presenti informazioni su supporti.\n Follow-up: Non sono presenti indicazioni per follow-up.\n Educazione al proprietario:\n\t+ I risultati indicano che il cane è in buone condizioni e non ci sono segni di gravità o emergenza. Sebbene sia importante monitorare i valori dei parametri ematochimici, non ci sono indicazioni per esami aggiuntivi o terapia iniziale/supporto.\n\t+ Si consiglia una visita clinica veterinaria per un'analisi completa e personalizzata del cane."}
---\ No newline at end of file
---diff --git a/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/bbd74c69-cc51-4a69-88dc-baf48f7dc057._page_1.png b/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/bbd74c69-cc51-4a69-88dc-baf48f7dc057._page_1.png
---deleted file mode 100644
---index c12dfc0..0000000
---Binary files a/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/bbd74c69-cc51-4a69-88dc-baf48f7dc057._page_1.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/bbd74c69-cc51-4a69-88dc-baf48f7dc057._page_2.png b/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/bbd74c69-cc51-4a69-88dc-baf48f7dc057._page_2.png
---deleted file mode 100644
---index bd9351e..0000000
---Binary files a/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/bbd74c69-cc51-4a69-88dc-baf48f7dc057._page_2.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/bbd74c69-cc51-4a69-88dc-baf48f7dc057._page_3.png b/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/bbd74c69-cc51-4a69-88dc-baf48f7dc057._page_3.png
---deleted file mode 100644
---index 1eb3eb4..0000000
---Binary files a/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/bbd74c69-cc51-4a69-88dc-baf48f7dc057._page_3.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/bbd74c69-cc51-4a69-88dc-baf48f7dc057._page_4.png b/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/bbd74c69-cc51-4a69-88dc-baf48f7dc057._page_4.png
---deleted file mode 100644
---index 33ae6c5..0000000
---Binary files a/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/bbd74c69-cc51-4a69-88dc-baf48f7dc057._page_4.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/model_output.json b/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/model_output.json
---deleted file mode 100644
---index 71eaa99..0000000
------ a/data/blood_work_pdfs/bbd74c69-cc51-4a69-88dc-baf48f7dc057/model_output.json
---+++ /dev/null
---@@ -1 +0,0 @@
----{"result": "1. Tabella dei parametri\n\n| Parametro | Valore misurato | Unità | Range di riferimento | Evidenziazione |\n| --- | --- | --- | --- | --- |\n| BUN/Creatinina | 20 mg/dL | mg/dL | 15-30 mg/dL | ✅ normale |\n| Calcio/Fosforo | 2.5 mg/dL | mg/dL | 2.0-4.0 mg/dL | ✅ normale |\n| Neutrofili/Linfociti | 70% | % | 60-80% | ✅ normale |\n| Na/K | 150 mEq/L | mEq/L | 140-160 mEq/L | ✅ normale |\n| Albumina/Globuline | 3.5 g/dL | g/dL | 3.0-4.5 g/dL | ✅ normale |\n\n2. Analisi matematica\n\n BUN/Creatinina: Valore all'interno del range di riferimento, quindi normale.\n Calcio/Fosforo: Valore all'interno del range di riferimento, quindi normale.\n Neutrofili/Linfociti: Valore all'interno del range di riferimento, quindi normale.\n Na/K: Valore all'interno del range di riferimento, quindi normale.\n Albumina/Globuline: Valore all'interno del range di riferimento, quindi normale.\n\n3. Interpretazione clinica\n\n Non sono presenti alterazioni significative.\n\n4. Interpretazione citologica/istologica\n\n Non sono presenti referti citologici/istologici da interpretare.\n\n5. Classificazione dell’urgenza\n\n Routine.\n\n6. Piano diagnostico\n\n Esami aggiuntivi:\n\t+ Priorità: Alta\n\t+ Invasività: Media\n\t+ Farmaci (mg/kg, via, durata): Non disponibili\n\t+ Supplementi/diete raccomandate: Non disponibili\n\t+ Supporti (SAMe, fluidoterapia, ecc.): Non disponibili\n\t+ Follow-up: Quando ripetere esami\n\t+ Segni clinici da monitorare: Non disponibili\n\t+ Indicazioni prognostiche: Non disponibili\n\t+ Educazione al proprietario: Non disponibili\n\t+ Bandierine rosse: Non disponibili\n\t+ Contesto: Non disponibili\n\t+ Fonti rapide: Non disponibili\n\t+ Disclaimer finale: Analisi automatica basata su referto. Non sostituisce visita clinica veterinaria. Si consiglia valutazione medica diretta."}
---\ No newline at end of file
---diff --git a/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/c0db1b42-95a3-46aa-a127-b8c4e5db6056._page_1.png b/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/c0db1b42-95a3-46aa-a127-b8c4e5db6056._page_1.png
---deleted file mode 100644
---index c12dfc0..0000000
---Binary files a/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/c0db1b42-95a3-46aa-a127-b8c4e5db6056._page_1.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/c0db1b42-95a3-46aa-a127-b8c4e5db6056._page_2.png b/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/c0db1b42-95a3-46aa-a127-b8c4e5db6056._page_2.png
---deleted file mode 100644
---index bd9351e..0000000
---Binary files a/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/c0db1b42-95a3-46aa-a127-b8c4e5db6056._page_2.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/c0db1b42-95a3-46aa-a127-b8c4e5db6056._page_3.png b/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/c0db1b42-95a3-46aa-a127-b8c4e5db6056._page_3.png
---deleted file mode 100644
---index 1eb3eb4..0000000
---Binary files a/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/c0db1b42-95a3-46aa-a127-b8c4e5db6056._page_3.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/c0db1b42-95a3-46aa-a127-b8c4e5db6056._page_4.png b/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/c0db1b42-95a3-46aa-a127-b8c4e5db6056._page_4.png
---deleted file mode 100644
---index 33ae6c5..0000000
---Binary files a/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/c0db1b42-95a3-46aa-a127-b8c4e5db6056._page_4.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/model_output.json b/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/model_output.json
---deleted file mode 100644
---index 9b7cb51..0000000
------ a/data/blood_work_pdfs/c0db1b42-95a3-46aa-a127-b8c4e5db6056/model_output.json
---+++ /dev/null
---@@ -1 +0,0 @@
----{"result": "1. Tabella dei parametri\n\n| Parametro | Valore misurato | Unità | Range di riferimento | Evidenziazione |\n| --- | --- | --- | --- | --- |\n| BUN/Creatinina | 20 mg/dL | mg/dL | 15-30 mg/dL | ✅ normale |\n| Calcio/Fosforo | 2.5 mmol/L | mmol/L | 2.0-4.0 mmol/L | ✅ normale |\n| Neutrofili/Linfociti | 70% | % | 60-80% | ✅ normale |\n| Na/K | 150 mEq/L | mEq/L | 140-160 mEq/L | ✅ normale |\n| Albumina/Globuline | 3.5 g/dL | g/dL | 3.0-4.5 g/dL | ✅ normale |\n\n2. Analisi matematica\n\n BUN/Creatinina: Valore all'interno del range di riferimento, quindi normale.\n Calcio/Fosforo: Valore all'interno del range di riferimento, quindi normale.\n Neutrofili/Linfociti: Valore all'interno del range di riferimento, quindi normale.\n Na/K: Valore all'interno del range di riferimento, quindi normale.\n Albumina/Globuline: Valore all'interno del range di riferimento, quindi normale.\n\n3. Interpretazione clinica\n\n Non sono presenti alterazioni significative.\n\n4. Interpretazione citologico-istologica\n\n Non sono presenti referti citologici o istologici.\n\n5. Classificazione dell’urgenza\n\n Routine.\n\n6. Piano diagnostico\n\n Esami aggiuntivi:\n\t+ Priorità: Alta\n\t+ Invasività: Media\n Farmaci (mg/kg, via, durata):\n\t+ Supplementi raccomandati: SAMe, fluidoterapia, ecc.\n Supporti (SAMe, fluidoterapia, ecc.):\n\t+ Fluidoterapia\n Follow-up:\n\t+ Quando ripetere esami: 1 mese\n\t+ Segni clinici da monitorare: Peso, comportamento, sintomi di dolore o discomfort\n\t+ Indicazioni prognostiche: Monitoraggio periodico del peso e della condizione generale.\n Educazione al proprietario:\n\t+ I risultati indicano che il cane è in buona salute. Se la situazione è grave o gestibile, si consiglia una visita clinica veterinaria per un'analisi più approfondita e per un piano di cura personalizzato.\n Bandierine rosse:\n\t+ PLT < 100: Non presente\n\t+ WBC < 4: Non presente\n\t+ Na < 130: Non presente\n\t+ K+ > 6.0: Non presente\n Contesto:\n\t+ Digiuno, stress da trasporto: Non presente\n\t+ Farmaci in uso: Non presente\n\t+ Età, razza, stagione: Non presente\n\t+ Fonti rapide: Non presente\n Disclaimer finale:\n\t+ Analisi automatica basata su referto. Non sostituisce visita clinica veterinaria. Si consiglia valutazione medica diretta."}
---\ No newline at end of file
---diff --git a/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/fafebc21-4a4b-40fc-b40a-b1406ad8ad22._page_1.png b/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/fafebc21-4a4b-40fc-b40a-b1406ad8ad22._page_1.png
---deleted file mode 100644
---index c12dfc0..0000000
---Binary files a/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/fafebc21-4a4b-40fc-b40a-b1406ad8ad22._page_1.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/fafebc21-4a4b-40fc-b40a-b1406ad8ad22._page_2.png b/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/fafebc21-4a4b-40fc-b40a-b1406ad8ad22._page_2.png
---deleted file mode 100644
---index bd9351e..0000000
---Binary files a/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/fafebc21-4a4b-40fc-b40a-b1406ad8ad22._page_2.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/fafebc21-4a4b-40fc-b40a-b1406ad8ad22._page_3.png b/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/fafebc21-4a4b-40fc-b40a-b1406ad8ad22._page_3.png
---deleted file mode 100644
---index 1eb3eb4..0000000
---Binary files a/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/fafebc21-4a4b-40fc-b40a-b1406ad8ad22._page_3.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/fafebc21-4a4b-40fc-b40a-b1406ad8ad22._page_4.png b/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/fafebc21-4a4b-40fc-b40a-b1406ad8ad22._page_4.png
---deleted file mode 100644
---index 33ae6c5..0000000
---Binary files a/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/fafebc21-4a4b-40fc-b40a-b1406ad8ad22._page_4.png and /dev/null differ
---diff --git a/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/model_output.json b/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/model_output.json
---deleted file mode 100644
---index 2e78eed..0000000
------ a/data/blood_work_pdfs/fafebc21-4a4b-40fc-b40a-b1406ad8ad22/model_output.json
---+++ /dev/null
---@@ -1 +0,0 @@
----{"result": "1. Tabella dei parametri\n\n| Parametro | Valore misurato | Unità | Range di riferimento | Evidenziazione |\n| --- | --- | --- | --- | --- |\n| BUN/Creatinina | 20 mg/dL | mg/dL | 15-30 mg/dL | ✅ normale |\n| Calcio/Fosforo | 2.5 mmol/L | mmol/L | 2.0-4.5 mmol/L | ✅ normale |\n| Neutrofili/Linfociti | 70% | % | 60-80% | ✅ normale |\n| Na/K | 135 mEq/L | mEq/L | 130-145 mEq/L | ✅ normale |\n| Albumina/Globuline | 3.5 g/dL | g/dL | 3.0-4.5 g/dL | ✅ normale |\n\n2. Analisi matematica\n\n BUN/Creatinina: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n Calcio/Fosforo: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n Neutrofili/Linfociti: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n Na/K: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n Albumina/Globuline: Valore all'interno del range di riferimento, quindi non ci sono anomalie significative.\n\n3. Interpretazione clinica\n\nNon sono presenti alterazioni significative.\n\n4. Integrazione con citologia/istologia\n\nNon sono presenti referti citologici o istologici.\n\n5. Classificazione dell’urgenza\n\nRoutine.\n\n6. Piano diagnostico\n\n Priorità: Bassa\n Invasività: Bassa\n Farmaci (mg/kg, via, durata): Non sono stati somministrati farmaci.\n Supplementi/diete raccomandate: Non sono stati raccomandati supplementi o diete.\n Supporti (SAMe, fluidoterapia, ecc.): Non sono stati raccomandati supporti.\n Follow-up: Non è stato indicato un follow-up.\n Educazione al proprietario:\n\t+ I risultati indicano che il cane ha valori ematochimici all'interno del range di riferimento, quindi non ci sono segni di anemia o alterazioni significative. Se la situazione è grave o gestibile, si consiglia una visita clinica veterinaria per un esame completo e per eventuali ulteriori indagini.\n\t+ In caso di segni di discomfort o di altri problemi, si consiglia di controllare il cane con un esame medico diretto.\n\n7. Bandierine rosse\n\n PLT < 100: Non ci sono dati disponibili per valutare la presenza di piombo sanguigno (PLT) al di sotto dei 100.000/µL.\n WBC < 4: Non ci sono dati disponibili per valutare il numero di cellule bianche (WBC) al di sotto dei 4.000/µL.\n Na < 130: Non ci sono dati disponibili per valutare il sodio (Na) al di sotto dei 130 mEq/L.\n K+ > 6.0: Non ci sono dati disponibili per valutare il potassio (K+) al di sopra dei 6.0 mmol/L.\n\n8. Contesto\n\n Digiuno, stress da trasporto: Non ci sono dati disponibili per valutare la presenza di digiuno o stress da trasporto.\n Farmaci in uso: Non ci sono dati disponibili per valutare i farmaci in uso.\n Età, razza, stagione: Non ci sono dati disponibili per valutare l'età, la razza e la stagione.\n Fonti rapide: Non ci sono fonti rapide disponibili.\n\n9. Disclaimer finale\n\nL'analisi automatica basata su referto non sostituisce una visita clinica veterinaria. Si consiglia valutazione medica diretta per un esame completo e per eventuali ulteriori indagini."}
---\ No newline at end of file
---diff --git a/requirements.txt b/requirements.txt
---index d25867f..87eab50 100644
---Binary files a/requirements.txt and b/requirements.txt differ
--diff --git a/data/.DS_Store b/data/.DS_Store
--index becfc94..5008ddf 100644
--Binary files a/data/.DS_Store and b/data/.DS_Store differ
--diff --git a/data/blood_work_pdfs/.DS_Store b/data/blood_work_pdfs/.DS_Store
--deleted file mode 100644
--index 67c68a2..0000000
--Binary files a/data/blood_work_pdfs/.DS_Store and /dev/null differ
--diff --git a/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab._page_1.png b/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab._page_1.png
--deleted file mode 100644
--index c12dfc0..0000000
--Binary files a/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab._page_1.png and /dev/null differ
--diff --git a/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab._page_2.png b/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab._page_2.png
--deleted file mode 100644
--index bd9351e..0000000
--Binary files a/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab._page_2.png and /dev/null differ
--diff --git a/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab._page_3.png b/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab._page_3.png
--deleted file mode 100644
--index 1eb3eb4..0000000
--Binary files a/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab._page_3.png and /dev/null differ
--diff --git a/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab._page_4.png b/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab._page_4.png
--deleted file mode 100644
--index 33ae6c5..0000000
--Binary files a/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab._page_4.png and /dev/null differ
--diff --git a/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/model_output.json b/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/model_output.json
--deleted file mode 100644
--index d50b984..0000000
----- a/data/blood_work_pdfs/9edbdb81-34fd-4a5a-9667-a33ad4e2c5ab/model_output.json
--+++ /dev/null
--@@ -1 +0,0 @@
---{"result": "1. Tabella dei parametri\n\n| Parametro | Valore misurato | Unità | Range di riferimento | Evidenziazione |\n| --- | --- | --- | --- | --- |\n| BUN/Creatinina | 20 mg/dL | mg/dL | 15-35 mg/dL | ✅ normale |\n| Calcio/Fosforo | 2.5 mg/dL | mg/dL | 2.0-4.5 mg/dL | ✅ normale |\n| Neutrofili/Linfociti | 70% | % | 60-80% | ✅ normale |\n| Na/K | 135 mEq/L | mEq/L | 130-145 mEq/L | ✅ normale |\n| Albumina/Globuline | 3.5 g/dL | g/dL | 3.0-4.5 g/dL | ✅ normale |\n\n2. Analisi matematica\n\n BUN/Creatinina: Valore all'interno del range di riferimento, quindi normale.\n Calcio/Fosforo: Valore all'interno del range di riferimento, quindi normale.\n Neutrofili/Linfociti: Valore all'interno del range di riferimento, quindi normale.\n Na/K: Valore all'interno del range di riferimento, quindi normale.\n Albumina/Globuline: Valore all'interno del range di riferimento, quindi normale.\n\n3. Interpretazione clinica\n\n Non sono presenti alterazioni significative.\n\n4. Interpretazione citologica/istologica\n\n Non sono presenti referti citologici/istologici da interpretare.\n\n5. Classificazione dell'urgenza\n\n Routine.\n\n6. Piano diagnostico\n\n Esami aggiuntivi:\n\t+ Priorità: Alta\n\t+ Invasività: Media\n Farmaci (mg/kg, via, durata):\n\t+ Supplementi raccomandati: SAMe, fluidoterapia, ecc.\n Supporti (SAMe, fluidoterapia, ecc.):\n\t+ Fluidoterapia\n Follow-up:\n\t+ Quando ripetere esami: In 2 settimane\n\t+ Segni clinici da monitorare: Peso, comportamento, sintomi di dolore o discomfort\n\t+ Indicazioni prognostiche: Buona prognosi\n Educazione al proprietario:\n\t+ Cosa significano i risultati: I valori sono all'interno del range di riferimento e non ci sono alterazioni significative.\n\t+ Se la situazione è grave o gestibile: La situazione è normale e non ci sono segni di emergenza o urgenza.\n\t+ Quali passi fare ora: Non ci sono passi da fare ora.\n Bandierine rosse:\n\t+ PLT < 100, WBC < 4, Na < 130, K+ > 6.0: Non presenti.\n Contesto:\n\t+ Digiuno, stress da trasporto: Non ci sono dati su questi parametri.\n\t+ Farmaci in uso: Non ci sono dati su questi parametri.\n\t+ Età, razza, stagione: Non ci sono dati su questi parametri.\n Fonti rapide:\n\t+ IRIS 2023, Thrall 2012, AAHA 2021 oncology: Non ci sono referenze a queste fonti.\n Disclaimer finale:\n\t+ Analisi automatica basata su referto. Non sostituisce visita clinica veterinaria. Si consiglia valutazione medica diretta."}
--\ No newline at end of file
-diff --git a/requirements.txt b/requirements.txt
-index b71424c..f885fa4 100644
---- a/requirements.txt
-+++ b/requirements.txt
-@@ -1,14 +1,19 @@
- annotated-types==0.7.0
- anyio==4.9.0
-+bcrypt==4.3.0
- boto3==1.38.27
- botocore==1.38.37
- certifi==2025.6.15
-+cffi==1.17.1
- charset-normalizer==3.4.2
- click==8.2.0
- colorama==0.4.6
-+cryptography==45.0.4
- distro==1.9.0
- dnspython==2.7.0
- dotenv==0.9.9
-+ecdsa==0.19.1
-+email_validator==2.2.0
- fastapi==0.115.12
- h11==0.16.0
- httpcore==1.0.9
-@@ -18,14 +23,19 @@ jiter==0.10.0
- jmespath==1.0.1
- motor==3.7.1
- openai==1.84.0
-+passlib==1.7.4
-+pyasn1==0.6.1
-+pycparser==2.22
- pydantic==2.11.4
- pydantic_core==2.33.2
- pymongo==4.13.2
- PyMuPDF==1.26.0
- python-dateutil==2.9.0.post0
- python-dotenv==1.1.0
-+python-jose==3.5.0
- python-multipart==0.0.20
- requests==2.32.3
-+rsa==4.9.1
- s3transfer==0.13.0
- six==1.17.0
- sniffio==1.3.1
-diff --git a/run_server.py b/run_server.py
-index 6600c6e..e69de29 100644
---- a/run_server.py
-+++ b/run_server.py
-@@ -1,115 +0,0 @@
--#!/usr/bin/env python3
--"""
--Startup script for the Veterinary Bloodwork Analyzer.
--
--This script provides a simple way to start the application with proper
--configuration checks and helpful messages for developers.
--
--Usage:
--    python run_server.py [--dev] [--port PORT]
--"""
--
--import argparse
--import os
--import sys
--from pathlib import Path
--
--
--def check_environment() -> bool:
--    """
--    Check if the environment is properly configured.
--
--    Returns:
--        bool: True if environment is ready, False otherwise
--    """
--    issues = []
--
--    # Check for required directories
--    data_dir = Path("data/blood_work_pdfs")
--    if not data_dir.exists():
--        data_dir.mkdir(parents=True, exist_ok=True)
--        print(f"✅ Created data directory: {data_dir}")
--
--    # Check for OpenAI API key
--    if not os.getenv("OPENAI_API_KEY"):
--        issues.append(
--            "⚠️  OPENAI_API_KEY not set - AI analysis will not work"
--        )
--
--    # Check for prompt files
--    prompt_file = Path("app/prompts/diagnostic_prompt.txt")
--    if not prompt_file.exists():
--        issues.append(f"❌ Missing prompt file: {prompt_file}")
--
--    if issues:
--        print("\n🔧 Environment Issues Found:")
--        for issue in issues:
--            print(f"   {issue}")
--        print("\n💡 Add your API key to a .env file or environment variables")
--        return False
--
--    print("✅ Environment check passed!")
--    return True
--
--
--def main():
--    """Main entry point for the startup script."""
--    parser = argparse.ArgumentParser(
--        description="Start the Veterinary Bloodwork Analyzer")
--    parser.add_argument("--dev", action="store_true",
--                        help="Run in development mode")
--    parser.add_argument("--port", type=int, default=8000,
--                        help="Port to run on")
--    parser.add_argument("--host", default="0.0.0.0", help="Host to bind to")
--
--    args = parser.parse_args()
--
--    print("🐾 Veterinary Bloodwork Analyzer - Starting Up...")
--    print("=" * 50)
--
--    # Check environment
--    env_ok = check_environment()
--
--    # Import check
--    try:
--        from app.main import app  # noqa: F401
--        print("✅ Application modules loaded successfully")
--    except ImportError as e:
--        print(f"❌ Failed to import application: {e}")
--        sys.exit(1)
--
--    # Build uvicorn command
--    uvicorn_args = [
--        "uvicorn",
--        "app.main:app",
--        f"--host={args.host}",
--        f"--port={args.port}",
--    ]
--
--    if args.dev:
--        uvicorn_args.extend(["--reload", "--log-level=debug"])
--        print("🔧 Development mode enabled")
--
--    print(f"🚀 Starting server on http://{args.host}:{args.port}")
--    print("📖 API Documentation available at:")
--    print(f"   • Swagger UI: http://{args.host}:{args.port}/docs")
--    print(f"   • ReDoc: http://{args.host}:{args.port}/redoc")
--
--    if not env_ok:
--        print("\n⚠️  Starting with configuration issues - some features may not work")
--
--    print("\n" + "=" * 50)
--
--    # Start the server
--    import subprocess
--    try:
--        subprocess.run(uvicorn_args, check=True)
--    except KeyboardInterrupt:
--        print("\n👋 Server stopped by user")
--    except subprocess.CalledProcessError as e:
--        print(f"❌ Server failed to start: {e}")
--        sys.exit(1)
--
--
--if __name__ == "__main__":
--    main()
diff --git a/create_test_patient.py b/create_test_patient.py
deleted file mode 100644
index 0cb8ad0..0000000
--- a/create_test_patient.py
+++ /dev/null
@@ -1,86 +0,0 @@
-#!/usr/bin/env python3
-"""
-Script to create a test patient in the database for testing purposes.
-"""
-
-import asyncio
-import datetime
-from datetime import timezone
-
-from app.config.database_config import DatabaseConfig
-from app.repositories.repository_factory import RepositoryFactory
-from app.services.database_service import DatabaseService
-
-
-async def create_test_patient():
-    """Create a test patient in the database"""
-    # Connect to database
-    db_config = DatabaseConfig()
-    db_service = DatabaseService(db_config)
-
-    connected = await db_service.connect()
-    if not connected:
-        print("Failed to connect to database")
-        return
-
-    print("Connected to database successfully")
-
-    try:
-        # Create repository factory
-        repo_factory = RepositoryFactory(db_service)
-
-        # Generate patient ID using MongoDB's atomic operations
-        patient_id = await db_service.get_next_sequential_id("patient")
-
-        # Use datetime for birthdate since MongoDB can't handle Python date objects
-        birthdate = datetime.datetime(
-            2018, 5, 15, 0, 0, 0, tzinfo=timezone.utc)
-
-        # Create patient document directly for MongoDB
-        # This bypasses the Pydantic model validation that would convert datetime to date
-        patient_data = {
-            "_id": patient_id,
-            "name": "Max",
-            "species": "Canine",
-            "breed": "Golden Retriever",
-            "birthdate": birthdate,  # MongoDB can store this datetime
-            "sex": "Male",
-            "weight": 32.5,
-            "owner_info": {
-                "name": "John Doe",
-                "phone": "555-123-4567",
-                "email": "john.doe@example.com",
-                "address": "123 Main St, Anytown, USA"
-            },
-            "medical_history": {
-                "allergies": ["Chicken"],
-                "previous_conditions": ["Ear infection (2022)"],
-                "medications": ["Heartworm preventative"]
-            },
-            "created_by": "VET-001",
-            "assigned_to": "VET-001",
-            "created_at": datetime.datetime.now(timezone.utc),
-            "updated_at": datetime.datetime.now(timezone.utc),
-            "is_active": True
-        }
-
-        # Insert directly into collection
-        result = await db_service.patients.insert_one(patient_data)
-
-        if result.acknowledged:
-            print(f"Test patient created successfully with ID: {patient_id}")
-            print("Patient details: Max, Canine, Golden Retriever")
-        else:
-            print("Failed to create test patient")
-
-    except Exception as e:
-        print(f"Error creating test patient: {e}")
-
-    finally:
-        # Disconnect from database
-        await db_service.disconnect()
-        print("Disconnected from database")
-
-
-if __name__ == "__main__":
-    asyncio.run(create_test_patient())
